{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'C:\\Users\\vatti\\OneDrive\\Documents\\Classes\\HAP 880\\Week_1'\n",
    "os.chdir(root)\n",
    "\n",
    "df = pd.read_csv('highUtilizationPredictionV2wco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df.race))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['race',\n",
       " 'age',\n",
       " 'patient_id',\n",
       " 'ELIX1',\n",
       " 'ELIX2',\n",
       " 'ELIX3',\n",
       " 'ELIX4',\n",
       " 'ELIX5',\n",
       " 'ELIX6',\n",
       " 'ELIX7',\n",
       " 'ELIX8',\n",
       " 'ELIX9',\n",
       " 'ELIX10',\n",
       " 'ELIX11',\n",
       " 'ELIX12',\n",
       " 'ELIX13',\n",
       " 'ELIX14',\n",
       " 'ELIX15',\n",
       " 'ELIX16',\n",
       " 'ELIX17',\n",
       " 'ELIX18',\n",
       " 'ELIX19',\n",
       " 'ELIX20',\n",
       " 'ELIX21',\n",
       " 'ELIX22',\n",
       " 'ELIX23',\n",
       " 'ELIX24',\n",
       " 'ELIX25',\n",
       " 'ELIX26',\n",
       " 'ELIX27',\n",
       " 'ELIX28',\n",
       " 'ELIX29',\n",
       " 'G-2',\n",
       " 'G-3',\n",
       " 'G-4',\n",
       " 'G-5',\n",
       " 'G-6',\n",
       " 'G-7',\n",
       " 'G-8',\n",
       " 'G-9',\n",
       " 'G-10',\n",
       " 'G-11',\n",
       " 'G-12',\n",
       " 'G-13',\n",
       " 'G-14',\n",
       " 'G-15',\n",
       " 'G-16',\n",
       " 'G-17',\n",
       " 'G-18',\n",
       " 'G-19',\n",
       " 'G-20',\n",
       " 'G-21',\n",
       " 'G-22',\n",
       " 'G-23',\n",
       " 'drugs_m0-1',\n",
       " 'drugs_m1-2',\n",
       " 'drugs_m2-3',\n",
       " 'drugs_m3-4',\n",
       " 'drugs_m4-5',\n",
       " 'drugs_m5-6',\n",
       " 'drugs_m6-7',\n",
       " 'drugs_m7-8',\n",
       " 'drugs_m8-9',\n",
       " 'drugs_m9-10',\n",
       " 'drugs_m10-11',\n",
       " 'drugs_m11-12',\n",
       " 'HighUtilizationY2',\n",
       " 'claimCount',\n",
       " 'A',\n",
       " 'Am.N',\n",
       " 'B',\n",
       " 'H',\n",
       " 'O',\n",
       " 'U',\n",
       " 'W']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols_remove = ['race', 'patient_id', 'HighUtilizationY2', 'claimCount', 'index']\n",
    "\n",
    "sel = df[list(set(cols).difference(set(cols_remove)))]\n",
    "'''\n",
    "\n",
    "cols.remove('race')\n",
    "cols.remove('patient_id')\n",
    "cols.remove('HighUtilizationY2')\n",
    "cols.remove('claimCount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr, ts = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"C\": [1.0,0.8,0.5,0.3,0.01], \"solver\":['liblinear','lbfgs'], \"class_weight\":[None, 'balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.51837873, 1.5193572 , 1.44124007, 1.43484282, 1.4347899 ,\n",
       "        1.51902127, 1.50384188, 1.4725697 , 1.78892088, 1.58284903]),\n",
       " 'score_time': array([0.01561975, 0.03124022, 0.03124237, 0.02212644, 0.03124166,\n",
       "        0.02212739, 0.03124166, 0.03124166, 0.01561952, 0.02213335]),\n",
       " 'test_roc_auc': array([0.80078166, 0.82050576, 0.81700192, 0.79856848, 0.80448883,\n",
       "        0.80479378, 0.8153901 , 0.79923992, 0.80177837, 0.81534439]),\n",
       " 'test_accuracy': array([0.93665212, 0.93594432, 0.93806771, 0.93889348, 0.93535449,\n",
       "        0.93783178, 0.93712398, 0.93665212, 0.93865031, 0.93605474]),\n",
       " 'test_precision': array([0.54867257, 0.52631579, 0.63529412, 0.67045455, 0.5       ,\n",
       "        0.61052632, 0.59036145, 0.56790123, 0.64516129, 0.53521127]),\n",
       " 'test_recall': array([0.11313869, 0.09124088, 0.09854015, 0.10766423, 0.08029197,\n",
       "        0.10583942, 0.08941606, 0.08394161, 0.10968921, 0.06946984])}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_o = LogisticRegression()\n",
    "\n",
    "cross = cross_validate(lr, tr[cols], tr['HighUtilizationY2'], scoring=['roc_auc','accuracy','precision','recall'], cv=10)\n",
    "\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "res_lr = []\n",
    "for c in params[\"C\"]:\n",
    "    lr = LogisticRegression(C=c, solver='lbfgs', max_iter=100)\n",
    "    scores = [c, cross_validate(lr, tr[cols], tr['HighUtilizationY2'], scoring=['roc_auc','accuracy','precision','recall'], cv=10)]\n",
    "    res_lr.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  {'fit_time': array([1.69918466, 1.63518858, 1.67297411, 1.6105535 , 1.6729238 ,\n",
       "          1.73544288, 1.53491426, 1.75768089, 1.7889123 , 1.68854642]),\n",
       "   'score_time': array([0.03775454, 0.01561904, 0.01561642, 0.03125095, 0.03125405,\n",
       "          0.03774357, 0.03124166, 0.03124213, 0.01562119, 0.01562095]),\n",
       "   'test_roc_auc': array([0.80429666, 0.82024799, 0.81857358, 0.79895857, 0.80666393,\n",
       "          0.80927608, 0.81156095, 0.80231328, 0.80837416, 0.82341395]),\n",
       "   'test_accuracy': array([0.93724195, 0.93629822, 0.93889348, 0.93865754, 0.93582635,\n",
       "          0.93712398, 0.93700602, 0.93653415, 0.9368806 , 0.93463898]),\n",
       "   'test_precision': array([0.57017544, 0.54255319, 0.65306122, 0.64583333, 0.52040816,\n",
       "          0.56637168, 0.57      , 0.55681818, 0.55882353, 0.45454545]),\n",
       "   'test_recall': array([0.11861314, 0.09306569, 0.11678832, 0.11313869, 0.09306569,\n",
       "          0.11678832, 0.1040146 , 0.08941606, 0.10420475, 0.06398537])}],\n",
       " [0.8,\n",
       "  {'fit_time': array([1.71068501, 1.56616378, 1.61964297, 1.70420718, 1.77315402,\n",
       "          1.62613988, 1.53499818, 1.7575748 , 1.69015336, 1.61962223]),\n",
       "   'score_time': array([0.01562548, 0.02212787, 0.0156188 , 0.03124166, 0.03124237,\n",
       "          0.01562619, 0.03123832, 0.03123856, 0.03124166, 0.02212691]),\n",
       "   'test_roc_auc': array([0.80593391, 0.81909888, 0.81792089, 0.80676715, 0.80635899,\n",
       "          0.80639006, 0.81011058, 0.80264745, 0.80771774, 0.82121343]),\n",
       "   'test_accuracy': array([0.93700602, 0.93594432, 0.93912941, 0.93936534, 0.93535449,\n",
       "          0.93806771, 0.93724195, 0.93641618, 0.93699858, 0.93522888]),\n",
       "   'test_precision': array([0.5625    , 0.52252252, 0.66      , 0.68085106, 0.5       ,\n",
       "          0.62921348, 0.58695652, 0.5483871 , 0.55963303, 0.48809524]),\n",
       "   'test_recall': array([0.1149635 , 0.10583942, 0.12043796, 0.11678832, 0.09489051,\n",
       "          0.10218978, 0.09854015, 0.09306569, 0.11151737, 0.0749543 ])}],\n",
       " [0.5,\n",
       "  {'fit_time': array([1.85129905, 1.80447841, 1.73549533, 1.80444741, 1.88915396,\n",
       "          1.77323651, 1.64178991, 1.60402751, 1.65743065, 1.65080762]),\n",
       "   'score_time': array([0.02213335, 0.03124332, 0.02213264, 0.03124237, 0.01562023,\n",
       "          0.03124261, 0.01562572, 0.01562238, 0.01562619, 0.01561451]),\n",
       "   'test_roc_auc': array([0.80322649, 0.81889313, 0.81888358, 0.79948652, 0.80709223,\n",
       "          0.81396735, 0.81426699, 0.80189441, 0.80314355, 0.82314649]),\n",
       "   'test_accuracy': array([0.93735992, 0.93570839, 0.93865754, 0.93877551, 0.93559042,\n",
       "          0.93677008, 0.93641618, 0.93618025, 0.93817839, 0.93487494]),\n",
       "   'test_precision': array([0.568     , 0.51327434, 0.63207547, 0.65263158, 0.50909091,\n",
       "          0.55660377, 0.55294118, 0.53465347, 0.61616162, 0.4691358 ]),\n",
       "   'test_recall': array([0.12956204, 0.10583942, 0.12226277, 0.11313869, 0.10218978,\n",
       "          0.10766423, 0.08576642, 0.09854015, 0.11151737, 0.06946984])}],\n",
       " [0.3,\n",
       "  {'fit_time': array([1.58833933, 1.51939297, 1.50375938, 1.53500271, 1.50375152,\n",
       "          1.54149771, 1.47145724, 1.90443993, 1.89819717, 1.66648245]),\n",
       "   'score_time': array([0.01562667, 0.03124261, 0.0312407 , 0.03128123, 0.0312376 ,\n",
       "          0.03124213, 0.03124285, 0.02213001, 0.02213597, 0.02212524]),\n",
       "   'test_roc_auc': array([0.80341682, 0.81806024, 0.82308533, 0.80251477, 0.80531022,\n",
       "          0.80420484, 0.81160468, 0.7975067 , 0.8074127 , 0.82207736]),\n",
       "   'test_accuracy': array([0.93712398, 0.93570839, 0.93759585, 0.93865754, 0.93488262,\n",
       "          0.93724195, 0.93712398, 0.93712398, 0.93817839, 0.93522888]),\n",
       "   'test_precision': array([0.56521739, 0.51515152, 0.58558559, 0.65217391, 0.4787234 ,\n",
       "          0.58      , 0.58426966, 0.58241758, 0.62365591, 0.4875    ]),\n",
       "   'test_recall': array([0.11861314, 0.09306569, 0.11861314, 0.10948905, 0.08211679,\n",
       "          0.10583942, 0.09489051, 0.09671533, 0.10603291, 0.07129799])}],\n",
       " [0.01,\n",
       "  {'fit_time': array([1.58831692, 1.58835435, 1.51937389, 1.46596646, 1.48165703,\n",
       "          1.58179712, 1.5661869 , 1.50371885, 1.71990681, 1.84232187]),\n",
       "   'score_time': array([0.01561928, 0.03124332, 0.02213216, 0.03775096, 0.02213168,\n",
       "          0.02213144, 0.02212715, 0.03124809, 0.03124213, 0.03123927]),\n",
       "   'test_roc_auc': array([0.80078166, 0.82050576, 0.81700192, 0.79856848, 0.80448883,\n",
       "          0.80479378, 0.8153901 , 0.79923992, 0.80177837, 0.81534439]),\n",
       "   'test_accuracy': array([0.93665212, 0.93594432, 0.93806771, 0.93889348, 0.93535449,\n",
       "          0.93783178, 0.93712398, 0.93665212, 0.93865031, 0.93605474]),\n",
       "   'test_precision': array([0.54867257, 0.52631579, 0.63529412, 0.67045455, 0.5       ,\n",
       "          0.61052632, 0.59036145, 0.56790123, 0.64516129, 0.53521127]),\n",
       "   'test_recall': array([0.11313869, 0.09124088, 0.09854015, 0.10766423, 0.08029197,\n",
       "          0.10583942, 0.08941606, 0.08394161, 0.10968921, 0.06946984])}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(columns=[\"C\",\"solver\",\"score\",\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, {'fit_time': array([1.69918466, 1.63518858, 1.67297411, 1.6105535 , 1.6729238 ,\n",
      "       1.73544288, 1.53491426, 1.75768089, 1.7889123 , 1.68854642]), 'score_time': array([0.03775454, 0.01561904, 0.01561642, 0.03125095, 0.03125405,\n",
      "       0.03774357, 0.03124166, 0.03124213, 0.01562119, 0.01562095]), 'test_roc_auc': array([0.80429666, 0.82024799, 0.81857358, 0.79895857, 0.80666393,\n",
      "       0.80927608, 0.81156095, 0.80231328, 0.80837416, 0.82341395]), 'test_accuracy': array([0.93724195, 0.93629822, 0.93889348, 0.93865754, 0.93582635,\n",
      "       0.93712398, 0.93700602, 0.93653415, 0.9368806 , 0.93463898]), 'test_precision': array([0.57017544, 0.54255319, 0.65306122, 0.64583333, 0.52040816,\n",
      "       0.56637168, 0.57      , 0.55681818, 0.55882353, 0.45454545]), 'test_recall': array([0.11861314, 0.09306569, 0.11678832, 0.11313869, 0.09306569,\n",
      "       0.11678832, 0.1040146 , 0.08941606, 0.10420475, 0.06398537])}]\n",
      "[0.8, {'fit_time': array([1.71068501, 1.56616378, 1.61964297, 1.70420718, 1.77315402,\n",
      "       1.62613988, 1.53499818, 1.7575748 , 1.69015336, 1.61962223]), 'score_time': array([0.01562548, 0.02212787, 0.0156188 , 0.03124166, 0.03124237,\n",
      "       0.01562619, 0.03123832, 0.03123856, 0.03124166, 0.02212691]), 'test_roc_auc': array([0.80593391, 0.81909888, 0.81792089, 0.80676715, 0.80635899,\n",
      "       0.80639006, 0.81011058, 0.80264745, 0.80771774, 0.82121343]), 'test_accuracy': array([0.93700602, 0.93594432, 0.93912941, 0.93936534, 0.93535449,\n",
      "       0.93806771, 0.93724195, 0.93641618, 0.93699858, 0.93522888]), 'test_precision': array([0.5625    , 0.52252252, 0.66      , 0.68085106, 0.5       ,\n",
      "       0.62921348, 0.58695652, 0.5483871 , 0.55963303, 0.48809524]), 'test_recall': array([0.1149635 , 0.10583942, 0.12043796, 0.11678832, 0.09489051,\n",
      "       0.10218978, 0.09854015, 0.09306569, 0.11151737, 0.0749543 ])}]\n",
      "[0.5, {'fit_time': array([1.85129905, 1.80447841, 1.73549533, 1.80444741, 1.88915396,\n",
      "       1.77323651, 1.64178991, 1.60402751, 1.65743065, 1.65080762]), 'score_time': array([0.02213335, 0.03124332, 0.02213264, 0.03124237, 0.01562023,\n",
      "       0.03124261, 0.01562572, 0.01562238, 0.01562619, 0.01561451]), 'test_roc_auc': array([0.80322649, 0.81889313, 0.81888358, 0.79948652, 0.80709223,\n",
      "       0.81396735, 0.81426699, 0.80189441, 0.80314355, 0.82314649]), 'test_accuracy': array([0.93735992, 0.93570839, 0.93865754, 0.93877551, 0.93559042,\n",
      "       0.93677008, 0.93641618, 0.93618025, 0.93817839, 0.93487494]), 'test_precision': array([0.568     , 0.51327434, 0.63207547, 0.65263158, 0.50909091,\n",
      "       0.55660377, 0.55294118, 0.53465347, 0.61616162, 0.4691358 ]), 'test_recall': array([0.12956204, 0.10583942, 0.12226277, 0.11313869, 0.10218978,\n",
      "       0.10766423, 0.08576642, 0.09854015, 0.11151737, 0.06946984])}]\n",
      "[0.3, {'fit_time': array([1.58833933, 1.51939297, 1.50375938, 1.53500271, 1.50375152,\n",
      "       1.54149771, 1.47145724, 1.90443993, 1.89819717, 1.66648245]), 'score_time': array([0.01562667, 0.03124261, 0.0312407 , 0.03128123, 0.0312376 ,\n",
      "       0.03124213, 0.03124285, 0.02213001, 0.02213597, 0.02212524]), 'test_roc_auc': array([0.80341682, 0.81806024, 0.82308533, 0.80251477, 0.80531022,\n",
      "       0.80420484, 0.81160468, 0.7975067 , 0.8074127 , 0.82207736]), 'test_accuracy': array([0.93712398, 0.93570839, 0.93759585, 0.93865754, 0.93488262,\n",
      "       0.93724195, 0.93712398, 0.93712398, 0.93817839, 0.93522888]), 'test_precision': array([0.56521739, 0.51515152, 0.58558559, 0.65217391, 0.4787234 ,\n",
      "       0.58      , 0.58426966, 0.58241758, 0.62365591, 0.4875    ]), 'test_recall': array([0.11861314, 0.09306569, 0.11861314, 0.10948905, 0.08211679,\n",
      "       0.10583942, 0.09489051, 0.09671533, 0.10603291, 0.07129799])}]\n",
      "[0.01, {'fit_time': array([1.58831692, 1.58835435, 1.51937389, 1.46596646, 1.48165703,\n",
      "       1.58179712, 1.5661869 , 1.50371885, 1.71990681, 1.84232187]), 'score_time': array([0.01561928, 0.03124332, 0.02213216, 0.03775096, 0.02213168,\n",
      "       0.02213144, 0.02212715, 0.03124809, 0.03124213, 0.03123927]), 'test_roc_auc': array([0.80078166, 0.82050576, 0.81700192, 0.79856848, 0.80448883,\n",
      "       0.80479378, 0.8153901 , 0.79923992, 0.80177837, 0.81534439]), 'test_accuracy': array([0.93665212, 0.93594432, 0.93806771, 0.93889348, 0.93535449,\n",
      "       0.93783178, 0.93712398, 0.93665212, 0.93865031, 0.93605474]), 'test_precision': array([0.54867257, 0.52631579, 0.63529412, 0.67045455, 0.5       ,\n",
      "       0.61052632, 0.59036145, 0.56790123, 0.64516129, 0.53521127]), 'test_recall': array([0.11313869, 0.09124088, 0.09854015, 0.10766423, 0.08029197,\n",
      "       0.10583942, 0.08941606, 0.08394161, 0.10968921, 0.06946984])}]\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for r in res_lr:\n",
    "    for k,v in r[1].items():\n",
    "      l = [r[0]]\n",
    "      l.append('lbfgs')\n",
    "      l.append(k)\n",
    "      for i in v:\n",
    "            l.append(i)\n",
    "      res_df.loc[cnt]=l  \n",
    "      cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.699185</td>\n",
       "      <td>1.635189</td>\n",
       "      <td>1.672974</td>\n",
       "      <td>1.610554</td>\n",
       "      <td>1.672924</td>\n",
       "      <td>1.735443</td>\n",
       "      <td>1.534914</td>\n",
       "      <td>1.757681</td>\n",
       "      <td>1.788912</td>\n",
       "      <td>1.688546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>0.031254</td>\n",
       "      <td>0.037744</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.015621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.804297</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818574</td>\n",
       "      <td>0.798959</td>\n",
       "      <td>0.806664</td>\n",
       "      <td>0.809276</td>\n",
       "      <td>0.811561</td>\n",
       "      <td>0.802313</td>\n",
       "      <td>0.808374</td>\n",
       "      <td>0.823414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.936534</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>0.934639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.063985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.710685</td>\n",
       "      <td>1.566164</td>\n",
       "      <td>1.619643</td>\n",
       "      <td>1.704207</td>\n",
       "      <td>1.773154</td>\n",
       "      <td>1.626140</td>\n",
       "      <td>1.534998</td>\n",
       "      <td>1.757575</td>\n",
       "      <td>1.690153</td>\n",
       "      <td>1.619622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.022127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.805934</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>0.817921</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806390</td>\n",
       "      <td>0.810111</td>\n",
       "      <td>0.802647</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.821213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936999</td>\n",
       "      <td>0.935229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.488095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.074954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.851299</td>\n",
       "      <td>1.804478</td>\n",
       "      <td>1.735495</td>\n",
       "      <td>1.804447</td>\n",
       "      <td>1.889154</td>\n",
       "      <td>1.773237</td>\n",
       "      <td>1.641790</td>\n",
       "      <td>1.604028</td>\n",
       "      <td>1.657431</td>\n",
       "      <td>1.650808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.818893</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.799487</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.813967</td>\n",
       "      <td>0.814267</td>\n",
       "      <td>0.801894</td>\n",
       "      <td>0.803144</td>\n",
       "      <td>0.823146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.934875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.469136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.122263</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.107664</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.069470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.588339</td>\n",
       "      <td>1.519393</td>\n",
       "      <td>1.503759</td>\n",
       "      <td>1.535003</td>\n",
       "      <td>1.503752</td>\n",
       "      <td>1.541498</td>\n",
       "      <td>1.471457</td>\n",
       "      <td>1.904440</td>\n",
       "      <td>1.898197</td>\n",
       "      <td>1.666482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.022125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.803417</td>\n",
       "      <td>0.818060</td>\n",
       "      <td>0.823085</td>\n",
       "      <td>0.802515</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.804205</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>0.797507</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>0.822077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.934883</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.935229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.585586</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.106033</td>\n",
       "      <td>0.071298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.588317</td>\n",
       "      <td>1.588354</td>\n",
       "      <td>1.519374</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>1.481657</td>\n",
       "      <td>1.581797</td>\n",
       "      <td>1.566187</td>\n",
       "      <td>1.503719</td>\n",
       "      <td>1.719907</td>\n",
       "      <td>1.842322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.022131</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.800782</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>0.817002</td>\n",
       "      <td>0.798568</td>\n",
       "      <td>0.804489</td>\n",
       "      <td>0.804794</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.799240</td>\n",
       "      <td>0.801778</td>\n",
       "      <td>0.815344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.936055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.107664</td>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.109689</td>\n",
       "      <td>0.069470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C solver           score  score_val0  score_val1  score_val2  \\\n",
       "0   1.00  lbfgs        fit_time    1.699185    1.635189    1.672974   \n",
       "1   1.00  lbfgs      score_time    0.037755    0.015619    0.015616   \n",
       "2   1.00  lbfgs    test_roc_auc    0.804297    0.820248    0.818574   \n",
       "3   1.00  lbfgs   test_accuracy    0.937242    0.936298    0.938893   \n",
       "4   1.00  lbfgs  test_precision    0.570175    0.542553    0.653061   \n",
       "5   1.00  lbfgs     test_recall    0.118613    0.093066    0.116788   \n",
       "6   0.80  lbfgs        fit_time    1.710685    1.566164    1.619643   \n",
       "7   0.80  lbfgs      score_time    0.015625    0.022128    0.015619   \n",
       "8   0.80  lbfgs    test_roc_auc    0.805934    0.819099    0.817921   \n",
       "9   0.80  lbfgs   test_accuracy    0.937006    0.935944    0.939129   \n",
       "10  0.80  lbfgs  test_precision    0.562500    0.522523    0.660000   \n",
       "11  0.80  lbfgs     test_recall    0.114964    0.105839    0.120438   \n",
       "12  0.50  lbfgs        fit_time    1.851299    1.804478    1.735495   \n",
       "13  0.50  lbfgs      score_time    0.022133    0.031243    0.022133   \n",
       "14  0.50  lbfgs    test_roc_auc    0.803226    0.818893    0.818884   \n",
       "15  0.50  lbfgs   test_accuracy    0.937360    0.935708    0.938658   \n",
       "16  0.50  lbfgs  test_precision    0.568000    0.513274    0.632075   \n",
       "17  0.50  lbfgs     test_recall    0.129562    0.105839    0.122263   \n",
       "18  0.30  lbfgs        fit_time    1.588339    1.519393    1.503759   \n",
       "19  0.30  lbfgs      score_time    0.015627    0.031243    0.031241   \n",
       "20  0.30  lbfgs    test_roc_auc    0.803417    0.818060    0.823085   \n",
       "21  0.30  lbfgs   test_accuracy    0.937124    0.935708    0.937596   \n",
       "22  0.30  lbfgs  test_precision    0.565217    0.515152    0.585586   \n",
       "23  0.30  lbfgs     test_recall    0.118613    0.093066    0.118613   \n",
       "24  0.01  lbfgs        fit_time    1.588317    1.588354    1.519374   \n",
       "25  0.01  lbfgs      score_time    0.015619    0.031243    0.022132   \n",
       "26  0.01  lbfgs    test_roc_auc    0.800782    0.820506    0.817002   \n",
       "27  0.01  lbfgs   test_accuracy    0.936652    0.935944    0.938068   \n",
       "28  0.01  lbfgs  test_precision    0.548673    0.526316    0.635294   \n",
       "29  0.01  lbfgs     test_recall    0.113139    0.091241    0.098540   \n",
       "\n",
       "    score_val3  score_val4  score_val5  score_val6  score_val7  score_val8  \\\n",
       "0     1.610554    1.672924    1.735443    1.534914    1.757681    1.788912   \n",
       "1     0.031251    0.031254    0.037744    0.031242    0.031242    0.015621   \n",
       "2     0.798959    0.806664    0.809276    0.811561    0.802313    0.808374   \n",
       "3     0.938658    0.935826    0.937124    0.937006    0.936534    0.936881   \n",
       "4     0.645833    0.520408    0.566372    0.570000    0.556818    0.558824   \n",
       "5     0.113139    0.093066    0.116788    0.104015    0.089416    0.104205   \n",
       "6     1.704207    1.773154    1.626140    1.534998    1.757575    1.690153   \n",
       "7     0.031242    0.031242    0.015626    0.031238    0.031239    0.031242   \n",
       "8     0.806767    0.806359    0.806390    0.810111    0.802647    0.807718   \n",
       "9     0.939365    0.935354    0.938068    0.937242    0.936416    0.936999   \n",
       "10    0.680851    0.500000    0.629213    0.586957    0.548387    0.559633   \n",
       "11    0.116788    0.094891    0.102190    0.098540    0.093066    0.111517   \n",
       "12    1.804447    1.889154    1.773237    1.641790    1.604028    1.657431   \n",
       "13    0.031242    0.015620    0.031243    0.015626    0.015622    0.015626   \n",
       "14    0.799487    0.807092    0.813967    0.814267    0.801894    0.803144   \n",
       "15    0.938776    0.935590    0.936770    0.936416    0.936180    0.938178   \n",
       "16    0.652632    0.509091    0.556604    0.552941    0.534653    0.616162   \n",
       "17    0.113139    0.102190    0.107664    0.085766    0.098540    0.111517   \n",
       "18    1.535003    1.503752    1.541498    1.471457    1.904440    1.898197   \n",
       "19    0.031281    0.031238    0.031242    0.031243    0.022130    0.022136   \n",
       "20    0.802515    0.805310    0.804205    0.811605    0.797507    0.807413   \n",
       "21    0.938658    0.934883    0.937242    0.937124    0.937124    0.938178   \n",
       "22    0.652174    0.478723    0.580000    0.584270    0.582418    0.623656   \n",
       "23    0.109489    0.082117    0.105839    0.094891    0.096715    0.106033   \n",
       "24    1.465966    1.481657    1.581797    1.566187    1.503719    1.719907   \n",
       "25    0.037751    0.022132    0.022131    0.022127    0.031248    0.031242   \n",
       "26    0.798568    0.804489    0.804794    0.815390    0.799240    0.801778   \n",
       "27    0.938893    0.935354    0.937832    0.937124    0.936652    0.938650   \n",
       "28    0.670455    0.500000    0.610526    0.590361    0.567901    0.645161   \n",
       "29    0.107664    0.080292    0.105839    0.089416    0.083942    0.109689   \n",
       "\n",
       "    score_val9  \n",
       "0     1.688546  \n",
       "1     0.015621  \n",
       "2     0.823414  \n",
       "3     0.934639  \n",
       "4     0.454545  \n",
       "5     0.063985  \n",
       "6     1.619622  \n",
       "7     0.022127  \n",
       "8     0.821213  \n",
       "9     0.935229  \n",
       "10    0.488095  \n",
       "11    0.074954  \n",
       "12    1.650808  \n",
       "13    0.015615  \n",
       "14    0.823146  \n",
       "15    0.934875  \n",
       "16    0.469136  \n",
       "17    0.069470  \n",
       "18    1.666482  \n",
       "19    0.022125  \n",
       "20    0.822077  \n",
       "21    0.935229  \n",
       "22    0.487500  \n",
       "23    0.071298  \n",
       "24    1.842322  \n",
       "25    0.031239  \n",
       "26    0.815344  \n",
       "27    0.936055  \n",
       "28    0.535211  \n",
       "29    0.069470  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>solver</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.699185</td>\n",
       "      <td>1.635189</td>\n",
       "      <td>1.672974</td>\n",
       "      <td>1.610554</td>\n",
       "      <td>1.672924</td>\n",
       "      <td>1.735443</td>\n",
       "      <td>1.534914</td>\n",
       "      <td>1.757681</td>\n",
       "      <td>1.788912</td>\n",
       "      <td>1.688546</td>\n",
       "      <td>1.679632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.031251</td>\n",
       "      <td>0.031254</td>\n",
       "      <td>0.037744</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.026296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.804297</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818574</td>\n",
       "      <td>0.798959</td>\n",
       "      <td>0.806664</td>\n",
       "      <td>0.809276</td>\n",
       "      <td>0.811561</td>\n",
       "      <td>0.802313</td>\n",
       "      <td>0.808374</td>\n",
       "      <td>0.823414</td>\n",
       "      <td>0.810368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.936534</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>0.934639</td>\n",
       "      <td>0.936910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>0.542553</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.520408</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.563859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.063985</td>\n",
       "      <td>0.101308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.710685</td>\n",
       "      <td>1.566164</td>\n",
       "      <td>1.619643</td>\n",
       "      <td>1.704207</td>\n",
       "      <td>1.773154</td>\n",
       "      <td>1.626140</td>\n",
       "      <td>1.534998</td>\n",
       "      <td>1.757575</td>\n",
       "      <td>1.690153</td>\n",
       "      <td>1.619622</td>\n",
       "      <td>1.660234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.022128</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.024733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.805934</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>0.817921</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806390</td>\n",
       "      <td>0.810111</td>\n",
       "      <td>0.802647</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.821213</td>\n",
       "      <td>0.810416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936999</td>\n",
       "      <td>0.935229</td>\n",
       "      <td>0.937075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.559633</td>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.573816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.80</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.074954</td>\n",
       "      <td>0.103319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.851299</td>\n",
       "      <td>1.804478</td>\n",
       "      <td>1.735495</td>\n",
       "      <td>1.804447</td>\n",
       "      <td>1.889154</td>\n",
       "      <td>1.773237</td>\n",
       "      <td>1.641790</td>\n",
       "      <td>1.604028</td>\n",
       "      <td>1.657431</td>\n",
       "      <td>1.650808</td>\n",
       "      <td>1.741217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022133</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.015620</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015622</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.015615</td>\n",
       "      <td>0.021610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.818893</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.799487</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.813967</td>\n",
       "      <td>0.814267</td>\n",
       "      <td>0.801894</td>\n",
       "      <td>0.803144</td>\n",
       "      <td>0.823146</td>\n",
       "      <td>0.810400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.934875</td>\n",
       "      <td>0.936851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.513274</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.509091</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.534653</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.560457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.50</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.122263</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.107664</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.069470</td>\n",
       "      <td>0.104595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.588339</td>\n",
       "      <td>1.519393</td>\n",
       "      <td>1.503759</td>\n",
       "      <td>1.535003</td>\n",
       "      <td>1.503752</td>\n",
       "      <td>1.541498</td>\n",
       "      <td>1.471457</td>\n",
       "      <td>1.904440</td>\n",
       "      <td>1.898197</td>\n",
       "      <td>1.666482</td>\n",
       "      <td>1.613232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>0.022125</td>\n",
       "      <td>0.026951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.803417</td>\n",
       "      <td>0.818060</td>\n",
       "      <td>0.823085</td>\n",
       "      <td>0.802515</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.804205</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>0.797507</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>0.822077</td>\n",
       "      <td>0.809519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.934883</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.935229</td>\n",
       "      <td>0.936887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.585586</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.478723</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.565469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.30</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.106033</td>\n",
       "      <td>0.071298</td>\n",
       "      <td>0.099667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.588317</td>\n",
       "      <td>1.588354</td>\n",
       "      <td>1.519374</td>\n",
       "      <td>1.465966</td>\n",
       "      <td>1.481657</td>\n",
       "      <td>1.581797</td>\n",
       "      <td>1.566187</td>\n",
       "      <td>1.503719</td>\n",
       "      <td>1.719907</td>\n",
       "      <td>1.842322</td>\n",
       "      <td>1.585760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.031243</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.037751</td>\n",
       "      <td>0.022132</td>\n",
       "      <td>0.022131</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.031242</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.026687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.800782</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>0.817002</td>\n",
       "      <td>0.798568</td>\n",
       "      <td>0.804489</td>\n",
       "      <td>0.804794</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.799240</td>\n",
       "      <td>0.801778</td>\n",
       "      <td>0.815344</td>\n",
       "      <td>0.807789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.936055</td>\n",
       "      <td>0.937123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.548673</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.635294</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.610526</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.582990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.01</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.107664</td>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.109689</td>\n",
       "      <td>0.069470</td>\n",
       "      <td>0.094923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       C solver           score  score_val0  score_val1  score_val2  \\\n",
       "0   1.00  lbfgs        fit_time    1.699185    1.635189    1.672974   \n",
       "1   1.00  lbfgs      score_time    0.037755    0.015619    0.015616   \n",
       "2   1.00  lbfgs    test_roc_auc    0.804297    0.820248    0.818574   \n",
       "3   1.00  lbfgs   test_accuracy    0.937242    0.936298    0.938893   \n",
       "4   1.00  lbfgs  test_precision    0.570175    0.542553    0.653061   \n",
       "5   1.00  lbfgs     test_recall    0.118613    0.093066    0.116788   \n",
       "6   0.80  lbfgs        fit_time    1.710685    1.566164    1.619643   \n",
       "7   0.80  lbfgs      score_time    0.015625    0.022128    0.015619   \n",
       "8   0.80  lbfgs    test_roc_auc    0.805934    0.819099    0.817921   \n",
       "9   0.80  lbfgs   test_accuracy    0.937006    0.935944    0.939129   \n",
       "10  0.80  lbfgs  test_precision    0.562500    0.522523    0.660000   \n",
       "11  0.80  lbfgs     test_recall    0.114964    0.105839    0.120438   \n",
       "12  0.50  lbfgs        fit_time    1.851299    1.804478    1.735495   \n",
       "13  0.50  lbfgs      score_time    0.022133    0.031243    0.022133   \n",
       "14  0.50  lbfgs    test_roc_auc    0.803226    0.818893    0.818884   \n",
       "15  0.50  lbfgs   test_accuracy    0.937360    0.935708    0.938658   \n",
       "16  0.50  lbfgs  test_precision    0.568000    0.513274    0.632075   \n",
       "17  0.50  lbfgs     test_recall    0.129562    0.105839    0.122263   \n",
       "18  0.30  lbfgs        fit_time    1.588339    1.519393    1.503759   \n",
       "19  0.30  lbfgs      score_time    0.015627    0.031243    0.031241   \n",
       "20  0.30  lbfgs    test_roc_auc    0.803417    0.818060    0.823085   \n",
       "21  0.30  lbfgs   test_accuracy    0.937124    0.935708    0.937596   \n",
       "22  0.30  lbfgs  test_precision    0.565217    0.515152    0.585586   \n",
       "23  0.30  lbfgs     test_recall    0.118613    0.093066    0.118613   \n",
       "24  0.01  lbfgs        fit_time    1.588317    1.588354    1.519374   \n",
       "25  0.01  lbfgs      score_time    0.015619    0.031243    0.022132   \n",
       "26  0.01  lbfgs    test_roc_auc    0.800782    0.820506    0.817002   \n",
       "27  0.01  lbfgs   test_accuracy    0.936652    0.935944    0.938068   \n",
       "28  0.01  lbfgs  test_precision    0.548673    0.526316    0.635294   \n",
       "29  0.01  lbfgs     test_recall    0.113139    0.091241    0.098540   \n",
       "\n",
       "    score_val3  score_val4  score_val5  score_val6  score_val7  score_val8  \\\n",
       "0     1.610554    1.672924    1.735443    1.534914    1.757681    1.788912   \n",
       "1     0.031251    0.031254    0.037744    0.031242    0.031242    0.015621   \n",
       "2     0.798959    0.806664    0.809276    0.811561    0.802313    0.808374   \n",
       "3     0.938658    0.935826    0.937124    0.937006    0.936534    0.936881   \n",
       "4     0.645833    0.520408    0.566372    0.570000    0.556818    0.558824   \n",
       "5     0.113139    0.093066    0.116788    0.104015    0.089416    0.104205   \n",
       "6     1.704207    1.773154    1.626140    1.534998    1.757575    1.690153   \n",
       "7     0.031242    0.031242    0.015626    0.031238    0.031239    0.031242   \n",
       "8     0.806767    0.806359    0.806390    0.810111    0.802647    0.807718   \n",
       "9     0.939365    0.935354    0.938068    0.937242    0.936416    0.936999   \n",
       "10    0.680851    0.500000    0.629213    0.586957    0.548387    0.559633   \n",
       "11    0.116788    0.094891    0.102190    0.098540    0.093066    0.111517   \n",
       "12    1.804447    1.889154    1.773237    1.641790    1.604028    1.657431   \n",
       "13    0.031242    0.015620    0.031243    0.015626    0.015622    0.015626   \n",
       "14    0.799487    0.807092    0.813967    0.814267    0.801894    0.803144   \n",
       "15    0.938776    0.935590    0.936770    0.936416    0.936180    0.938178   \n",
       "16    0.652632    0.509091    0.556604    0.552941    0.534653    0.616162   \n",
       "17    0.113139    0.102190    0.107664    0.085766    0.098540    0.111517   \n",
       "18    1.535003    1.503752    1.541498    1.471457    1.904440    1.898197   \n",
       "19    0.031281    0.031238    0.031242    0.031243    0.022130    0.022136   \n",
       "20    0.802515    0.805310    0.804205    0.811605    0.797507    0.807413   \n",
       "21    0.938658    0.934883    0.937242    0.937124    0.937124    0.938178   \n",
       "22    0.652174    0.478723    0.580000    0.584270    0.582418    0.623656   \n",
       "23    0.109489    0.082117    0.105839    0.094891    0.096715    0.106033   \n",
       "24    1.465966    1.481657    1.581797    1.566187    1.503719    1.719907   \n",
       "25    0.037751    0.022132    0.022131    0.022127    0.031248    0.031242   \n",
       "26    0.798568    0.804489    0.804794    0.815390    0.799240    0.801778   \n",
       "27    0.938893    0.935354    0.937832    0.937124    0.936652    0.938650   \n",
       "28    0.670455    0.500000    0.610526    0.590361    0.567901    0.645161   \n",
       "29    0.107664    0.080292    0.105839    0.089416    0.083942    0.109689   \n",
       "\n",
       "    score_val9   average  \n",
       "0     1.688546  1.679632  \n",
       "1     0.015621  0.026296  \n",
       "2     0.823414  0.810368  \n",
       "3     0.934639  0.936910  \n",
       "4     0.454545  0.563859  \n",
       "5     0.063985  0.101308  \n",
       "6     1.619622  1.660234  \n",
       "7     0.022127  0.024733  \n",
       "8     0.821213  0.810416  \n",
       "9     0.935229  0.937075  \n",
       "10    0.488095  0.573816  \n",
       "11    0.074954  0.103319  \n",
       "12    1.650808  1.741217  \n",
       "13    0.015615  0.021610  \n",
       "14    0.823146  0.810400  \n",
       "15    0.934875  0.936851  \n",
       "16    0.469136  0.560457  \n",
       "17    0.069470  0.104595  \n",
       "18    1.666482  1.613232  \n",
       "19    0.022125  0.026951  \n",
       "20    0.822077  0.809519  \n",
       "21    0.935229  0.936887  \n",
       "22    0.487500  0.565469  \n",
       "23    0.071298  0.099667  \n",
       "24    1.842322  1.585760  \n",
       "25    0.031239  0.026687  \n",
       "26    0.815344  0.807789  \n",
       "27    0.936055  0.937123  \n",
       "28    0.535211  0.582990  \n",
       "29    0.069470  0.094923  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df['average'] = res_df[[\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\"]].mean(numeric_only=True, axis=1)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RF:  10 sqrt\n",
      "Running RF:  10 log2\n",
      "Running RF:  10 None\n",
      "Running RF:  55 sqrt\n",
      "Running RF:  55 log2\n",
      "Running RF:  55 None\n",
      "Running RF:  100 sqrt\n",
      "Running RF:  100 log2\n",
      "Running RF:  100 None\n",
      "Running RF:  200 sqrt\n",
      "Running RF:  200 log2\n",
      "Running RF:  200 None\n",
      "Running RF:  1000 sqrt\n",
      "Running RF:  1000 log2\n",
      "Running RF:  1000 None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "res_rf = []\n",
    "for t in list(map(int,np.linspace(10, 100, num=3)))+list(map(int,np.linspace(200, 1000, num=2))):\n",
    "    for f in [\"sqrt\",\"log2\",None]:\n",
    "      print('Running RF: ', t, f)\n",
    "      rf = RandomForestClassifier(n_estimators = t, max_features = f)\n",
    "      scores = [t, f, cross_validate(rf, tr[cols], tr['HighUtilizationY2'], scoring=['roc_auc','accuracy','precision','recall'], cv=10)]\n",
    "      res_rf.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 'sqrt',\n",
       " {'fit_time': array([1.11895633, 1.08745074, 1.09295869, 1.08941412, 1.01873326,\n",
       "         1.07212758, 1.08761668, 1.02462363, 1.03731394, 1.06532097]),\n",
       "  'score_time': array([0.06912327, 0.04691005, 0.05075407, 0.04689312, 0.05331635,\n",
       "         0.04680467, 0.0534122 , 0.05119824, 0.05100536, 0.05341506]),\n",
       "  'test_roc_auc': array([0.74614116, 0.73818103, 0.74055981, 0.74557086, 0.7188384 ,\n",
       "         0.73446799, 0.73634057, 0.73914891, 0.73906111, 0.7343932 ]),\n",
       "  'test_accuracy': array([0.93665212, 0.93700602, 0.93677008, 0.93794975, 0.93535449,\n",
       "         0.93641618, 0.93535449, 0.93629822, 0.93499292, 0.93558282]),\n",
       "  'test_precision': array([0.55670103, 0.57      , 0.55263158, 0.59482759, 0.5       ,\n",
       "         0.53982301, 0.5       , 0.53636364, 0.48039216, 0.50617284]),\n",
       "  'test_recall': array([0.09854015, 0.1040146 , 0.1149635 , 0.12591241, 0.10583942,\n",
       "         0.11131387, 0.10036496, 0.10766423, 0.08957952, 0.0749543 ])}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_rf = pd.DataFrame(columns=[\"Estimators\",\"max_features \",\"score\",\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for r in res_rf:\n",
    "    for k,v in r[2].items():\n",
    "        l = [r[0]]\n",
    "        l.append(r[1])\n",
    "        l.append(k)\n",
    "        for i in v:\n",
    "            l.append(i)\n",
    "        res_df_rf.loc[cnt]=l  \n",
    "        cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>1.118956</td>\n",
       "      <td>1.087451</td>\n",
       "      <td>1.092959</td>\n",
       "      <td>1.089414</td>\n",
       "      <td>1.018733</td>\n",
       "      <td>1.072128</td>\n",
       "      <td>1.087617</td>\n",
       "      <td>1.024624</td>\n",
       "      <td>1.037314</td>\n",
       "      <td>1.065321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>0.046910</td>\n",
       "      <td>0.050754</td>\n",
       "      <td>0.046893</td>\n",
       "      <td>0.053316</td>\n",
       "      <td>0.046805</td>\n",
       "      <td>0.053412</td>\n",
       "      <td>0.051198</td>\n",
       "      <td>0.051005</td>\n",
       "      <td>0.053415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.746141</td>\n",
       "      <td>0.738181</td>\n",
       "      <td>0.740560</td>\n",
       "      <td>0.745571</td>\n",
       "      <td>0.718838</td>\n",
       "      <td>0.734468</td>\n",
       "      <td>0.736341</td>\n",
       "      <td>0.739149</td>\n",
       "      <td>0.739061</td>\n",
       "      <td>0.734393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.937950</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.935583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.556701</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.539823</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.480392</td>\n",
       "      <td>0.506173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.125912</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.111314</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.107664</td>\n",
       "      <td>0.089580</td>\n",
       "      <td>0.074954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>0.908603</td>\n",
       "      <td>0.894595</td>\n",
       "      <td>0.933800</td>\n",
       "      <td>0.987520</td>\n",
       "      <td>0.949378</td>\n",
       "      <td>0.871353</td>\n",
       "      <td>0.913548</td>\n",
       "      <td>0.906700</td>\n",
       "      <td>0.933587</td>\n",
       "      <td>0.876129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.051137</td>\n",
       "      <td>0.062445</td>\n",
       "      <td>0.046904</td>\n",
       "      <td>0.053461</td>\n",
       "      <td>0.053414</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>0.050888</td>\n",
       "      <td>0.053459</td>\n",
       "      <td>0.051121</td>\n",
       "      <td>0.051034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.744672</td>\n",
       "      <td>0.742048</td>\n",
       "      <td>0.755982</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>0.727549</td>\n",
       "      <td>0.737194</td>\n",
       "      <td>0.734310</td>\n",
       "      <td>0.726975</td>\n",
       "      <td>0.731415</td>\n",
       "      <td>0.743713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.934293</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.936409</td>\n",
       "      <td>0.933813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.537634</td>\n",
       "      <td>0.518868</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.505155</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.431373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.095064</td>\n",
       "      <td>0.080439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>6.133052</td>\n",
       "      <td>6.186478</td>\n",
       "      <td>6.256935</td>\n",
       "      <td>5.892492</td>\n",
       "      <td>6.226705</td>\n",
       "      <td>5.926461</td>\n",
       "      <td>5.985945</td>\n",
       "      <td>5.619674</td>\n",
       "      <td>5.459140</td>\n",
       "      <td>5.644655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.040676</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>0.062440</td>\n",
       "      <td>0.069064</td>\n",
       "      <td>0.050565</td>\n",
       "      <td>0.054193</td>\n",
       "      <td>0.053421</td>\n",
       "      <td>0.050794</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>0.048928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.728383</td>\n",
       "      <td>0.733076</td>\n",
       "      <td>0.732353</td>\n",
       "      <td>0.746621</td>\n",
       "      <td>0.719202</td>\n",
       "      <td>0.732463</td>\n",
       "      <td>0.723697</td>\n",
       "      <td>0.735559</td>\n",
       "      <td>0.729290</td>\n",
       "      <td>0.738268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.933585</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.932877</td>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.932051</td>\n",
       "      <td>0.932523</td>\n",
       "      <td>0.930746</td>\n",
       "      <td>0.932869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.459893</td>\n",
       "      <td>0.503185</td>\n",
       "      <td>0.552795</td>\n",
       "      <td>0.524390</td>\n",
       "      <td>0.429530</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0.432927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.156934</td>\n",
       "      <td>0.144161</td>\n",
       "      <td>0.162409</td>\n",
       "      <td>0.156934</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.129562</td>\n",
       "      <td>0.138686</td>\n",
       "      <td>0.111517</td>\n",
       "      <td>0.129799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>5.817137</td>\n",
       "      <td>5.962093</td>\n",
       "      <td>6.032728</td>\n",
       "      <td>6.155559</td>\n",
       "      <td>5.668428</td>\n",
       "      <td>6.023432</td>\n",
       "      <td>5.977953</td>\n",
       "      <td>5.795522</td>\n",
       "      <td>5.357980</td>\n",
       "      <td>5.356719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.222707</td>\n",
       "      <td>0.231798</td>\n",
       "      <td>0.231846</td>\n",
       "      <td>0.216238</td>\n",
       "      <td>0.231766</td>\n",
       "      <td>0.247377</td>\n",
       "      <td>0.200651</td>\n",
       "      <td>0.200635</td>\n",
       "      <td>0.200653</td>\n",
       "      <td>0.204426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.786675</td>\n",
       "      <td>0.800861</td>\n",
       "      <td>0.807812</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>0.773550</td>\n",
       "      <td>0.787498</td>\n",
       "      <td>0.788065</td>\n",
       "      <td>0.794755</td>\n",
       "      <td>0.797085</td>\n",
       "      <td>0.809547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.938540</td>\n",
       "      <td>0.938304</td>\n",
       "      <td>0.938060</td>\n",
       "      <td>0.938650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.635514</td>\n",
       "      <td>0.606742</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.640777</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.601852</td>\n",
       "      <td>0.658824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>0.098540</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.124088</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.118830</td>\n",
       "      <td>0.102377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>4.605118</td>\n",
       "      <td>4.902403</td>\n",
       "      <td>4.945445</td>\n",
       "      <td>4.902788</td>\n",
       "      <td>4.916699</td>\n",
       "      <td>4.487720</td>\n",
       "      <td>4.485998</td>\n",
       "      <td>4.546525</td>\n",
       "      <td>4.566281</td>\n",
       "      <td>4.707593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.231814</td>\n",
       "      <td>0.216227</td>\n",
       "      <td>0.238350</td>\n",
       "      <td>0.231801</td>\n",
       "      <td>0.205875</td>\n",
       "      <td>0.212966</td>\n",
       "      <td>0.212368</td>\n",
       "      <td>0.216218</td>\n",
       "      <td>0.200647</td>\n",
       "      <td>0.222758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.792981</td>\n",
       "      <td>0.805060</td>\n",
       "      <td>0.801548</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.780378</td>\n",
       "      <td>0.793028</td>\n",
       "      <td>0.790320</td>\n",
       "      <td>0.791270</td>\n",
       "      <td>0.811157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938186</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.939719</td>\n",
       "      <td>0.939011</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.939011</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.938768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.602273</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>55</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>0.095064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>16.341666</td>\n",
       "      <td>16.044900</td>\n",
       "      <td>15.990095</td>\n",
       "      <td>15.936256</td>\n",
       "      <td>16.360462</td>\n",
       "      <td>15.871430</td>\n",
       "      <td>16.037751</td>\n",
       "      <td>15.974150</td>\n",
       "      <td>16.333932</td>\n",
       "      <td>15.956479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.708832</td>\n",
       "      <td>0.709883</td>\n",
       "      <td>0.701344</td>\n",
       "      <td>0.709183</td>\n",
       "      <td>0.700639</td>\n",
       "      <td>0.701713</td>\n",
       "      <td>0.740194</td>\n",
       "      <td>0.708706</td>\n",
       "      <td>0.706285</td>\n",
       "      <td>0.702127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.795275</td>\n",
       "      <td>0.812491</td>\n",
       "      <td>0.818446</td>\n",
       "      <td>0.809490</td>\n",
       "      <td>0.787672</td>\n",
       "      <td>0.797592</td>\n",
       "      <td>0.805200</td>\n",
       "      <td>0.804410</td>\n",
       "      <td>0.798647</td>\n",
       "      <td>0.819828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938540</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.940191</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.938304</td>\n",
       "      <td>0.937471</td>\n",
       "      <td>0.938060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>200</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.105839</td>\n",
       "      <td>0.080292</td>\n",
       "      <td>0.093066</td>\n",
       "      <td>0.113139</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.094891</td>\n",
       "      <td>0.095064</td>\n",
       "      <td>0.082267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>110.921603</td>\n",
       "      <td>112.662632</td>\n",
       "      <td>109.345405</td>\n",
       "      <td>110.220329</td>\n",
       "      <td>110.800723</td>\n",
       "      <td>109.201674</td>\n",
       "      <td>109.768491</td>\n",
       "      <td>109.166251</td>\n",
       "      <td>112.071297</td>\n",
       "      <td>111.454576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>score_time</td>\n",
       "      <td>0.655056</td>\n",
       "      <td>0.597352</td>\n",
       "      <td>0.586348</td>\n",
       "      <td>0.588942</td>\n",
       "      <td>0.597727</td>\n",
       "      <td>0.594635</td>\n",
       "      <td>0.589183</td>\n",
       "      <td>0.597672</td>\n",
       "      <td>0.699554</td>\n",
       "      <td>0.611908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.776482</td>\n",
       "      <td>0.790338</td>\n",
       "      <td>0.790766</td>\n",
       "      <td>0.796532</td>\n",
       "      <td>0.770960</td>\n",
       "      <td>0.781975</td>\n",
       "      <td>0.787274</td>\n",
       "      <td>0.789622</td>\n",
       "      <td>0.786783</td>\n",
       "      <td>0.796133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.937235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.626866</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.610294</td>\n",
       "      <td>0.559701</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>200</td>\n",
       "      <td>None</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.169708</td>\n",
       "      <td>0.144161</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.164234</td>\n",
       "      <td>0.151460</td>\n",
       "      <td>0.136861</td>\n",
       "      <td>0.135283</td>\n",
       "      <td>0.127971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>94.516969</td>\n",
       "      <td>99.982409</td>\n",
       "      <td>96.839321</td>\n",
       "      <td>94.898454</td>\n",
       "      <td>94.327135</td>\n",
       "      <td>94.678246</td>\n",
       "      <td>94.074149</td>\n",
       "      <td>94.748965</td>\n",
       "      <td>94.334752</td>\n",
       "      <td>98.024969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>score_time</td>\n",
       "      <td>3.431288</td>\n",
       "      <td>3.716913</td>\n",
       "      <td>3.449535</td>\n",
       "      <td>3.404776</td>\n",
       "      <td>3.486390</td>\n",
       "      <td>3.426828</td>\n",
       "      <td>3.491493</td>\n",
       "      <td>3.437567</td>\n",
       "      <td>3.949226</td>\n",
       "      <td>3.479297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.800090</td>\n",
       "      <td>0.814969</td>\n",
       "      <td>0.818398</td>\n",
       "      <td>0.809501</td>\n",
       "      <td>0.788415</td>\n",
       "      <td>0.799124</td>\n",
       "      <td>0.808064</td>\n",
       "      <td>0.808881</td>\n",
       "      <td>0.803981</td>\n",
       "      <td>0.821989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.940781</td>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.938422</td>\n",
       "      <td>0.939483</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.937588</td>\n",
       "      <td>0.938532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.671053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.120438</td>\n",
       "      <td>0.111314</td>\n",
       "      <td>0.102190</td>\n",
       "      <td>0.125912</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.096715</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.093236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>80.293811</td>\n",
       "      <td>80.712674</td>\n",
       "      <td>80.660620</td>\n",
       "      <td>80.523283</td>\n",
       "      <td>80.502491</td>\n",
       "      <td>80.347826</td>\n",
       "      <td>80.352554</td>\n",
       "      <td>80.315007</td>\n",
       "      <td>79.936958</td>\n",
       "      <td>82.292175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>score_time</td>\n",
       "      <td>3.540811</td>\n",
       "      <td>3.473031</td>\n",
       "      <td>3.490090</td>\n",
       "      <td>3.449601</td>\n",
       "      <td>3.470271</td>\n",
       "      <td>3.523841</td>\n",
       "      <td>3.483726</td>\n",
       "      <td>3.476963</td>\n",
       "      <td>3.456686</td>\n",
       "      <td>4.084950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.815206</td>\n",
       "      <td>0.821785</td>\n",
       "      <td>0.807109</td>\n",
       "      <td>0.788168</td>\n",
       "      <td>0.801651</td>\n",
       "      <td>0.809229</td>\n",
       "      <td>0.807862</td>\n",
       "      <td>0.804587</td>\n",
       "      <td>0.820974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.940073</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.939719</td>\n",
       "      <td>0.938186</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.938060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.581395</td>\n",
       "      <td>0.633803</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1000</td>\n",
       "      <td>log2</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.100365</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>0.109489</td>\n",
       "      <td>0.091241</td>\n",
       "      <td>0.082117</td>\n",
       "      <td>0.111314</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.087751</td>\n",
       "      <td>0.080439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>552.275908</td>\n",
       "      <td>555.584401</td>\n",
       "      <td>553.404690</td>\n",
       "      <td>553.167660</td>\n",
       "      <td>556.813340</td>\n",
       "      <td>546.784014</td>\n",
       "      <td>553.159365</td>\n",
       "      <td>551.855919</td>\n",
       "      <td>552.260560</td>\n",
       "      <td>555.357749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>score_time</td>\n",
       "      <td>3.003084</td>\n",
       "      <td>2.913853</td>\n",
       "      <td>2.895003</td>\n",
       "      <td>2.995579</td>\n",
       "      <td>2.945674</td>\n",
       "      <td>2.899099</td>\n",
       "      <td>2.990373</td>\n",
       "      <td>2.939268</td>\n",
       "      <td>2.917212</td>\n",
       "      <td>3.272853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.779183</td>\n",
       "      <td>0.795268</td>\n",
       "      <td>0.793676</td>\n",
       "      <td>0.797219</td>\n",
       "      <td>0.772475</td>\n",
       "      <td>0.783602</td>\n",
       "      <td>0.793319</td>\n",
       "      <td>0.795336</td>\n",
       "      <td>0.788563</td>\n",
       "      <td>0.801476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.939247</td>\n",
       "      <td>0.939837</td>\n",
       "      <td>0.935237</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.937950</td>\n",
       "      <td>0.937478</td>\n",
       "      <td>0.935701</td>\n",
       "      <td>0.936999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.584000</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.639706</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.562092</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.506757</td>\n",
       "      <td>0.552000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1000</td>\n",
       "      <td>None</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.175182</td>\n",
       "      <td>0.133212</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.158759</td>\n",
       "      <td>0.136861</td>\n",
       "      <td>0.156934</td>\n",
       "      <td>0.142336</td>\n",
       "      <td>0.136861</td>\n",
       "      <td>0.137112</td>\n",
       "      <td>0.126143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estimators max_features            score  score_val0  score_val1  \\\n",
       "0          10          sqrt        fit_time    1.118956    1.087451   \n",
       "1          10          sqrt      score_time    0.069123    0.046910   \n",
       "2          10          sqrt    test_roc_auc    0.746141    0.738181   \n",
       "3          10          sqrt   test_accuracy    0.936652    0.937006   \n",
       "4          10          sqrt  test_precision    0.556701    0.570000   \n",
       "5          10          sqrt     test_recall    0.098540    0.104015   \n",
       "6          10          log2        fit_time    0.908603    0.894595   \n",
       "7          10          log2      score_time    0.051137    0.062445   \n",
       "8          10          log2    test_roc_auc    0.744672    0.742048   \n",
       "9          10          log2   test_accuracy    0.935590    0.935590   \n",
       "10         10          log2  test_precision    0.509434    0.510417   \n",
       "11         10          log2     test_recall    0.098540    0.089416   \n",
       "12         10          None        fit_time    6.133052    6.186478   \n",
       "13         10          None      score_time    0.040676    0.046909   \n",
       "14         10          None    test_roc_auc    0.728383    0.733076   \n",
       "15         10          None   test_accuracy    0.933585    0.935472   \n",
       "16         10          None  test_precision    0.459893    0.503185   \n",
       "17         10          None     test_recall    0.156934    0.144161   \n",
       "18         55          sqrt        fit_time    5.817137    5.962093   \n",
       "19         55          sqrt      score_time    0.222707    0.231798   \n",
       "20         55          sqrt    test_roc_auc    0.786675    0.800861   \n",
       "21         55          sqrt   test_accuracy    0.938776    0.937596   \n",
       "22         55          sqrt  test_precision    0.635514    0.606742   \n",
       "23         55          sqrt     test_recall    0.124088    0.098540   \n",
       "24         55          log2        fit_time    4.605118    4.902403   \n",
       "25         55          log2      score_time    0.231814    0.216227   \n",
       "26         55          log2    test_roc_auc    0.792981    0.805060   \n",
       "27         55          log2   test_accuracy    0.938186    0.937006   \n",
       "28         55          log2  test_precision    0.639535    0.581395   \n",
       "29         55          log2     test_recall    0.100365    0.091241   \n",
       "..        ...           ...             ...         ...         ...   \n",
       "60        200          log2        fit_time   16.341666   16.044900   \n",
       "61        200          log2      score_time    0.708832    0.709883   \n",
       "62        200          log2    test_roc_auc    0.795275    0.812491   \n",
       "63        200          log2   test_accuracy    0.938540    0.937596   \n",
       "64        200          log2  test_precision    0.651685    0.637681   \n",
       "65        200          log2     test_recall    0.105839    0.080292   \n",
       "66        200          None        fit_time  110.921603  112.662632   \n",
       "67        200          None      score_time    0.655056    0.597352   \n",
       "68        200          None    test_roc_auc    0.776482    0.790338   \n",
       "69        200          None   test_accuracy    0.938893    0.937832   \n",
       "70        200          None  test_precision    0.596154    0.576642   \n",
       "71        200          None     test_recall    0.169708    0.144161   \n",
       "72       1000          sqrt        fit_time   94.516969   99.982409   \n",
       "73       1000          sqrt      score_time    3.431288    3.716913   \n",
       "74       1000          sqrt    test_roc_auc    0.800090    0.814969   \n",
       "75       1000          sqrt   test_accuracy    0.939365    0.938893   \n",
       "76       1000          sqrt  test_precision    0.673469    0.663043   \n",
       "77       1000          sqrt     test_recall    0.120438    0.111314   \n",
       "78       1000          log2        fit_time   80.293811   80.712674   \n",
       "79       1000          log2      score_time    3.540811    3.473031   \n",
       "80       1000          log2    test_roc_auc    0.801136    0.815206   \n",
       "81       1000          log2   test_accuracy    0.938776    0.937832   \n",
       "82       1000          log2  test_precision    0.679012    0.652174   \n",
       "83       1000          log2     test_recall    0.100365    0.082117   \n",
       "84       1000          None        fit_time  552.275908  555.584401   \n",
       "85       1000          None      score_time    3.003084    2.913853   \n",
       "86       1000          None    test_roc_auc    0.779183    0.795268   \n",
       "87       1000          None   test_accuracy    0.938893    0.937832   \n",
       "88       1000          None  test_precision    0.592593    0.584000   \n",
       "89       1000          None     test_recall    0.175182    0.133212   \n",
       "\n",
       "    score_val2  score_val3  score_val4  score_val5  score_val6  score_val7  \\\n",
       "0     1.092959    1.089414    1.018733    1.072128    1.087617    1.024624   \n",
       "1     0.050754    0.046893    0.053316    0.046805    0.053412    0.051198   \n",
       "2     0.740560    0.745571    0.718838    0.734468    0.736341    0.739149   \n",
       "3     0.936770    0.937950    0.935354    0.936416    0.935354    0.936298   \n",
       "4     0.552632    0.594828    0.500000    0.539823    0.500000    0.536364   \n",
       "5     0.114964    0.125912    0.105839    0.111314    0.100365    0.107664   \n",
       "6     0.933800    0.987520    0.949378    0.871353    0.913548    0.906700   \n",
       "7     0.046904    0.053461    0.053414    0.046908    0.050888    0.053459   \n",
       "8     0.755982    0.742725    0.727549    0.737194    0.734310    0.726975   \n",
       "9     0.936180    0.935826    0.935590    0.934293    0.937006    0.935472   \n",
       "10    0.537634    0.518868    0.510204    0.457944    0.568627    0.505155   \n",
       "11    0.091241    0.100365    0.091241    0.089416    0.105839    0.089416   \n",
       "12    6.256935    5.892492    6.226705    5.926461    5.985945    5.619674   \n",
       "13    0.062440    0.069064    0.050565    0.054193    0.053421    0.050794   \n",
       "14    0.732353    0.746621    0.719202    0.732463    0.723697    0.735559   \n",
       "15    0.937360    0.936298    0.932877    0.933231    0.932051    0.932523   \n",
       "16    0.552795    0.524390    0.429530    0.451613    0.417647    0.431818   \n",
       "17    0.162409    0.156934    0.116788    0.153285    0.129562    0.138686   \n",
       "18    6.032728    6.155559    5.668428    6.023432    5.977953    5.795522   \n",
       "19    0.231846    0.216238    0.231766    0.247377    0.200651    0.200635   \n",
       "20    0.807812    0.801343    0.773550    0.787498    0.788065    0.794755   \n",
       "21    0.939247    0.939247    0.937478    0.938776    0.938540    0.938304   \n",
       "22    0.703704    0.660194    0.588235    0.640777    0.636364    0.631579   \n",
       "23    0.104015    0.124088    0.109489    0.120438    0.114964    0.109489   \n",
       "24    4.945445    4.902788    4.916699    4.487720    4.485998    4.546525   \n",
       "25    0.238350    0.231801    0.205875    0.212966    0.212368    0.216218   \n",
       "26    0.801548    0.799038    0.778502    0.780378    0.793028    0.790320   \n",
       "27    0.939719    0.939011    0.936298    0.937478    0.939011    0.937478   \n",
       "28    0.712644    0.663158    0.543478    0.602273    0.663158    0.621622   \n",
       "29    0.113139    0.114964    0.091241    0.096715    0.114964    0.083942   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "60   15.990095   15.936256   16.360462   15.871430   16.037751   15.974150   \n",
       "61    0.701344    0.709183    0.700639    0.701713    0.740194    0.708706   \n",
       "62    0.818446    0.809490    0.787672    0.797592    0.805200    0.804410   \n",
       "63    0.938776    0.940191    0.936298    0.937596    0.939365    0.938304   \n",
       "64    0.698630    0.746988    0.543478    0.617284    0.712500    0.658228   \n",
       "65    0.093066    0.113139    0.091241    0.091241    0.104015    0.094891   \n",
       "66  109.345405  110.220329  110.800723  109.201674  109.768491  109.166251   \n",
       "67    0.586348    0.588942    0.597727    0.594635    0.589183    0.597672   \n",
       "68    0.790766    0.796532    0.770960    0.781975    0.787274    0.789622   \n",
       "69    0.939365    0.939129    0.935826    0.937832    0.938893    0.937242   \n",
       "70    0.626866    0.617647    0.512658    0.566038    0.610294    0.559701   \n",
       "71    0.153285    0.153285    0.147810    0.164234    0.151460    0.136861   \n",
       "72   96.839321   94.898454   94.327135   94.678246   94.074149   94.748965   \n",
       "73    3.449535    3.404776    3.486390    3.426828    3.491493    3.437567   \n",
       "74    0.818398    0.809501    0.788415    0.799124    0.808064    0.808881   \n",
       "75    0.939365    0.940781    0.937360    0.938422    0.939483    0.938068   \n",
       "76    0.717949    0.750000    0.595506    0.662500    0.692308    0.626374   \n",
       "77    0.102190    0.125912    0.096715    0.096715    0.114964    0.104015   \n",
       "78   80.660620   80.523283   80.502491   80.347826   80.352554   80.315007   \n",
       "79    3.490090    3.449601    3.470271    3.523841    3.483726    3.476963   \n",
       "80    0.821785    0.807109    0.788168    0.801651    0.809229    0.807862   \n",
       "81    0.938068    0.940073    0.937006    0.937596    0.939719    0.938186   \n",
       "82    0.671642    0.750000    0.581395    0.633803    0.717647    0.662162   \n",
       "83    0.082117    0.109489    0.091241    0.082117    0.111314    0.089416   \n",
       "84  553.404690  553.167660  556.813340  546.784014  553.159365  551.855919   \n",
       "85    2.895003    2.995579    2.945674    2.899099    2.990373    2.939268   \n",
       "86    0.793676    0.797219    0.772475    0.783602    0.793319    0.795336   \n",
       "87    0.939247    0.939837    0.935237    0.937596    0.937950    0.937478   \n",
       "88    0.627907    0.639706    0.496689    0.562092    0.582090    0.568182   \n",
       "89    0.147810    0.158759    0.136861    0.156934    0.142336    0.136861   \n",
       "\n",
       "    score_val8  score_val9  \n",
       "0     1.037314    1.065321  \n",
       "1     0.051005    0.053415  \n",
       "2     0.739061    0.734393  \n",
       "3     0.934993    0.935583  \n",
       "4     0.480392    0.506173  \n",
       "5     0.089580    0.074954  \n",
       "6     0.933587    0.876129  \n",
       "7     0.051121    0.051034  \n",
       "8     0.731415    0.743713  \n",
       "9     0.936409    0.933813  \n",
       "10    0.541667    0.431373  \n",
       "11    0.095064    0.080439  \n",
       "12    5.459140    5.644655  \n",
       "13    0.051032    0.048928  \n",
       "14    0.729290    0.738268  \n",
       "15    0.930746    0.932869  \n",
       "16    0.376543    0.432927  \n",
       "17    0.111517    0.129799  \n",
       "18    5.357980    5.356719  \n",
       "19    0.200653    0.204426  \n",
       "20    0.797085    0.809547  \n",
       "21    0.938060    0.938650  \n",
       "22    0.601852    0.658824  \n",
       "23    0.118830    0.102377  \n",
       "24    4.566281    4.707593  \n",
       "25    0.200647    0.222758  \n",
       "26    0.791270    0.811157  \n",
       "27    0.937471    0.938768  \n",
       "28    0.591398    0.684211  \n",
       "29    0.100548    0.095064  \n",
       "..         ...         ...  \n",
       "60   16.333932   15.956479  \n",
       "61    0.706285    0.702127  \n",
       "62    0.798647    0.819828  \n",
       "63    0.937471    0.938060  \n",
       "64    0.597701    0.661765  \n",
       "65    0.095064    0.082267  \n",
       "66  112.071297  111.454576  \n",
       "67    0.699554    0.611908  \n",
       "68    0.786783    0.796133  \n",
       "69    0.934993    0.937235  \n",
       "70    0.486842    0.560000  \n",
       "71    0.135283    0.127971  \n",
       "72   94.334752   98.024969  \n",
       "73    3.949226    3.479297  \n",
       "74    0.803981    0.821989  \n",
       "75    0.937588    0.938532  \n",
       "76    0.593750    0.671053  \n",
       "77    0.104205    0.093236  \n",
       "78   79.936958   82.292175  \n",
       "79    3.456686    4.084950  \n",
       "80    0.804587    0.820974  \n",
       "81    0.937235    0.938060  \n",
       "82    0.592593    0.666667  \n",
       "83    0.087751    0.080439  \n",
       "84  552.260560  555.357749  \n",
       "85    2.917212    3.272853  \n",
       "86    0.788563    0.801476  \n",
       "87    0.935701    0.936999  \n",
       "88    0.506757    0.552000  \n",
       "89    0.137112    0.126143  \n",
       "\n",
       "[90 rows x 13 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer, Categorical, Real\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "space = [Integer(10, 20, name='n_estimators'),\n",
    "         Categorical(['sqrt', 'log2'], name='max_features'),\n",
    "         Categorical(['gini','entropy'], name='criterion')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    return -np.mean(cross_val_score(rf, tr[cols], tr['HighUtilizationY2'], cv=5, n_jobs=1, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80390919, 0.80779857, 0.78698342, 0.79917104, 0.8004819 ])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_o = RandomForestClassifier()\n",
    "\n",
    "scores_rf = cross_val_score(rf_o, tr[cols], tr['HighUtilizationY2'], cv=5, n_jobs=1, scoring='roc_auc')\n",
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 6.1292\n",
      "Function value obtained: -0.7559\n",
      "Current minimum: -0.7559\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 5.9323\n",
      "Function value obtained: -0.7479\n",
      "Current minimum: -0.7559\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 4.8394\n",
      "Function value obtained: -0.7468\n",
      "Current minimum: -0.7559\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 7.0540\n",
      "Function value obtained: -0.7536\n",
      "Current minimum: -0.7559\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 4.4607\n",
      "Function value obtained: -0.7359\n",
      "Current minimum: -0.7559\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 7.5508\n",
      "Function value obtained: -0.7613\n",
      "Current minimum: -0.7613\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 5.3081\n",
      "Function value obtained: -0.7460\n",
      "Current minimum: -0.7613\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 4.7257\n",
      "Function value obtained: -0.7377\n",
      "Current minimum: -0.7613\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 4.4852\n",
      "Function value obtained: -0.7424\n",
      "Current minimum: -0.7613\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 6.9608\n",
      "Function value obtained: -0.7607\n",
      "Current minimum: -0.7613\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5310\n",
      "Function value obtained: -0.7670\n",
      "Current minimum: -0.7670\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1914\n",
      "Function value obtained: -0.7695\n",
      "Current minimum: -0.7695\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0002\n",
      "Function value obtained: -0.7694\n",
      "Current minimum: -0.7695\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0157\n",
      "Function value obtained: -0.7700\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0619\n",
      "Function value obtained: -0.7696\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.9831\n",
      "Function value obtained: -0.7684\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0225\n",
      "Function value obtained: -0.7678\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1495\n",
      "Function value obtained: -0.7694\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3013\n",
      "Function value obtained: -0.7696\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8569\n",
      "Function value obtained: -0.7686\n",
      "Current minimum: -0.7700\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3110\n",
      "Function value obtained: -0.7703\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3940\n",
      "Function value obtained: -0.7670\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0834\n",
      "Function value obtained: -0.7690\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0529\n",
      "Function value obtained: -0.7682\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1558\n",
      "Function value obtained: -0.7687\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7956\n",
      "Function value obtained: -0.7684\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1529\n",
      "Function value obtained: -0.7701\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1723\n",
      "Function value obtained: -0.7694\n",
      "Current minimum: -0.7703\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2988\n",
      "Function value obtained: -0.7705\n",
      "Current minimum: -0.7705\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3253\n",
      "Function value obtained: -0.7634\n",
      "Current minimum: -0.7705\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2208\n",
      "Function value obtained: -0.7702\n",
      "Current minimum: -0.7705\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0966\n",
      "Function value obtained: -0.7706\n",
      "Current minimum: -0.7706\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2737\n",
      "Function value obtained: -0.7665\n",
      "Current minimum: -0.7706\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3440\n",
      "Function value obtained: -0.7709\n",
      "Current minimum: -0.7709\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1489\n",
      "Function value obtained: -0.7738\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8781\n",
      "Function value obtained: -0.7593\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.4133\n",
      "Function value obtained: -0.7661\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4336\n",
      "Function value obtained: -0.7705\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1607\n",
      "Function value obtained: -0.7678\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2468\n",
      "Function value obtained: -0.7677\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2761\n",
      "Function value obtained: -0.7702\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0131\n",
      "Function value obtained: -0.7679\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1952\n",
      "Function value obtained: -0.7677\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2039\n",
      "Function value obtained: -0.7711\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3430\n",
      "Function value obtained: -0.7604\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0078\n",
      "Function value obtained: -0.7676\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2348\n",
      "Function value obtained: -0.7697\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.1753\n",
      "Function value obtained: -0.7702\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0402\n",
      "Function value obtained: -0.7712\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4045\n",
      "Function value obtained: -0.7690\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1759\n",
      "Function value obtained: -0.7695\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3801\n",
      "Function value obtained: -0.7716\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1641\n",
      "Function value obtained: -0.7700\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3453\n",
      "Function value obtained: -0.7687\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3490\n",
      "Function value obtained: -0.7696\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3837\n",
      "Function value obtained: -0.7657\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0878\n",
      "Function value obtained: -0.7609\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1686\n",
      "Function value obtained: -0.7686\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2923\n",
      "Function value obtained: -0.7688\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6451\n",
      "Function value obtained: -0.7674\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5999\n",
      "Function value obtained: -0.7669\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1782\n",
      "Function value obtained: -0.7628\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2432\n",
      "Function value obtained: -0.7615\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1605\n",
      "Function value obtained: -0.7673\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3189\n",
      "Function value obtained: -0.7684\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4957\n",
      "Function value obtained: -0.7678\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1667\n",
      "Function value obtained: -0.7665\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4659\n",
      "Function value obtained: -0.7658\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0546\n",
      "Function value obtained: -0.7636\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4883\n",
      "Function value obtained: -0.7715\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2395\n",
      "Function value obtained: -0.7616\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1277\n",
      "Function value obtained: -0.7701\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.4516\n",
      "Function value obtained: -0.7712\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.1680\n",
      "Function value obtained: -0.7616\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2730\n",
      "Function value obtained: -0.7678\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 76 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 76 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.8305\n",
      "Function value obtained: -0.7704\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 77 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 77 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5416\n",
      "Function value obtained: -0.7695\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 78 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 78 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3908\n",
      "Function value obtained: -0.7706\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 79 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 79 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8051\n",
      "Function value obtained: -0.7681\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 80 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 80 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5538\n",
      "Function value obtained: -0.7708\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 81 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 81 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2484\n",
      "Function value obtained: -0.7693\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 82 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 82 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.5684\n",
      "Function value obtained: -0.7673\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 83 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 83 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8153\n",
      "Function value obtained: -0.7622\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 84 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 84 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6279\n",
      "Function value obtained: -0.7723\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 85 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 85 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.7559\n",
      "Function value obtained: -0.7699\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 86 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 86 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3139\n",
      "Function value obtained: -0.7673\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 87 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 87 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3749\n",
      "Function value obtained: -0.7619\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 88 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 88 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.6979\n",
      "Function value obtained: -0.7661\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 89 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 89 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8421\n",
      "Function value obtained: -0.7676\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 90 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 90 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.8475\n",
      "Function value obtained: -0.7672\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 91 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 91 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.5107\n",
      "Function value obtained: -0.7670\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 92 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 92 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5207\n",
      "Function value obtained: -0.7634\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 93 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 93 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2397\n",
      "Function value obtained: -0.7634\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 94 started. Searching for the next optimal point.\n",
      "Iteration No: 94 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.2037\n",
      "Function value obtained: -0.7342\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 95 started. Searching for the next optimal point.\n",
      "Iteration No: 95 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.3076\n",
      "Function value obtained: -0.7600\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 96 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 96 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.2794\n",
      "Function value obtained: -0.7706\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 97 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 97 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.4929\n",
      "Function value obtained: -0.7686\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 98 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 98 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.4131\n",
      "Function value obtained: -0.7663\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 99 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 99 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.9711\n",
      "Function value obtained: -0.7713\n",
      "Current minimum: -0.7738\n",
      "Iteration No: 100 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vatti\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 100 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.5764\n",
      "Function value obtained: -0.7667\n",
      "Current minimum: -0.7738\n"
     ]
    }
   ],
   "source": [
    "reg_gp = gp_minimize(objective, space, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          fun: -0.7738354590677058\n",
       "    func_vals: array([-0.75589439, -0.74794812, -0.74682476, -0.75362978, -0.73590579,\n",
       "       -0.76125024, -0.74597705, -0.73769791, -0.74241041, -0.76070281,\n",
       "       -0.76702804, -0.76949868, -0.76944875, -0.77003381, -0.76961592,\n",
       "       -0.76837103, -0.76777954, -0.76939648, -0.76962068, -0.7686335 ,\n",
       "       -0.77030233, -0.76700565, -0.76901722, -0.7681606 , -0.76870887,\n",
       "       -0.7684047 , -0.77005113, -0.76937257, -0.77052485, -0.76343548,\n",
       "       -0.77023171, -0.7706138 , -0.76652716, -0.77092179, -0.77383546,\n",
       "       -0.75932041, -0.76611267, -0.77054555, -0.76784316, -0.76765192,\n",
       "       -0.77016714, -0.76792515, -0.76768802, -0.77108645, -0.76041942,\n",
       "       -0.76761883, -0.76966901, -0.77021095, -0.77119844, -0.76899806,\n",
       "       -0.76946562, -0.77160473, -0.76995047, -0.7686811 , -0.76957515,\n",
       "       -0.7657377 , -0.76094686, -0.76859784, -0.76877831, -0.76740204,\n",
       "       -0.76692801, -0.76282128, -0.76154979, -0.76725967, -0.76840496,\n",
       "       -0.76778233, -0.76645809, -0.76577267, -0.76359414, -0.77152959,\n",
       "       -0.76164694, -0.77013654, -0.77124103, -0.76161467, -0.76779146,\n",
       "       -0.77039085, -0.76945216, -0.77055651, -0.76808176, -0.7708025 ,\n",
       "       -0.76931308, -0.76725331, -0.76217215, -0.77228884, -0.76993263,\n",
       "       -0.76734193, -0.76193587, -0.76608199, -0.76761421, -0.76723654,\n",
       "       -0.76698304, -0.76337117, -0.76342741, -0.73423659, -0.75995788,\n",
       "       -0.77063576, -0.76861091, -0.76626942, -0.77130196, -0.76672225])\n",
       "       models: [GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664)]\n",
       " random_state: <mtrand.RandomState object at 0x000001A8C87A8990>\n",
       "        space: Space([Integer(low=10, high=20, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('sqrt', 'log2'), prior=None),\n",
       "       Categorical(categories=('gini', 'entropy'), prior=None)])\n",
       "        specs: {'args': {'func': <function objective at 0x000001A88006A510>, 'dimensions': Space([Integer(low=10, high=20, prior='uniform', transform='normalize'),\n",
       "       Categorical(categories=('sqrt', 'log2'), prior=None),\n",
       "       Categorical(categories=('gini', 'entropy'), prior=None)]), 'base_estimator': GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
       "                         kernel=1**2 * Matern(length_scale=[1, 1, 1], nu=2.5),\n",
       "                         n_restarts_optimizer=2, noise='gaussian',\n",
       "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
       "                         random_state=1820675664), 'n_calls': 100, 'n_random_starts': 10, 'acq_func': 'gp_hedge', 'acq_optimizer': 'auto', 'x0': None, 'y0': None, 'random_state': <mtrand.RandomState object at 0x000001A8C87A8990>, 'verbose': True, 'callback': None, 'n_points': 10000, 'n_restarts_optimizer': 5, 'xi': 0.01, 'kappa': 1.96, 'n_jobs': 1, 'model_queue_size': None}, 'function': 'base_minimize'}\n",
       "            x: [20, 'log2', 'entropy']\n",
       "      x_iters: [[13, 'sqrt', 'entropy'], [12, 'sqrt', 'entropy'], [12, 'log2', 'gini'], [15, 'sqrt', 'entropy'], [10, 'log2', 'gini'], [16, 'sqrt', 'entropy'], [11, 'sqrt', 'entropy'], [10, 'sqrt', 'gini'], [11, 'log2', 'gini'], [16, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'entropy'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'entropy'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'sqrt', 'entropy'], [20, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [18, 'log2', 'gini'], [20, 'sqrt', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [20, 'log2', 'entropy'], [17, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [17, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'sqrt', 'entropy'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [17, 'log2', 'gini'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [17, 'log2', 'entropy'], [17, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [17, 'log2', 'entropy'], [17, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [17, 'log2', 'entropy'], [20, 'log2', 'gini'], [20, 'sqrt', 'gini'], [17, 'sqrt', 'gini'], [20, 'log2', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [20, 'sqrt', 'entropy'], [17, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [17, 'sqrt', 'gini'], [20, 'log2', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'gini'], [20, 'log2', 'gini'], [17, 'log2', 'entropy'], [17, 'sqrt', 'gini'], [10, 'log2', 'entropy'], [17, 'sqrt', 'entropy'], [20, 'log2', 'gini'], [20, 'sqrt', 'gini'], [20, 'sqrt', 'entropy'], [20, 'sqrt', 'entropy'], [20, 'log2', 'gini']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = {'n': [5, 10, 15, 20], 'weights': ['uniform', 'distance'], 'algorithm':['ball_tree', 'kd_tree']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_knn = []\n",
    "\n",
    "for est in tune['n']:\n",
    "    knn = KNeighborsClassifier(n_neighbors = est, weights = 'uniform', algorithm = 'kd_tree')\n",
    "    scores = [est, cross_validate (knn, tr[cols], tr['HighUtilizationY2'], scoring = ['roc_auc','accuracy','precision','recall'], cv=10)]\n",
    "    res_knn.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  {'fit_time': array([3.34601116, 3.24049997, 3.24618697, 3.38266563, 3.29857922,\n",
       "          3.30074906, 3.30811906, 3.52370191, 3.59257531, 3.63062954]),\n",
       "   'score_time': array([31.2281692 , 31.40613604, 31.33348012, 30.43230963, 30.84942341,\n",
       "          31.04741025, 31.17636299, 31.9583807 , 30.93987083, 30.00223899]),\n",
       "   'test_roc_auc': array([0.63189951, 0.64887579, 0.65422677, 0.65432792, 0.61991599,\n",
       "          0.63699273, 0.64093039, 0.62274746, 0.62658102, 0.65369136]),\n",
       "   'test_accuracy': array([0.93205143, 0.93582635, 0.93299516, 0.93393889, 0.93157957,\n",
       "          0.93476466, 0.9321694 , 0.9332311 , 0.93416706, 0.9339311 ]),\n",
       "   'test_precision': array([0.35416667, 0.53125   , 0.37804878, 0.425     , 0.32978723,\n",
       "          0.4691358 , 0.36082474, 0.39285714, 0.42465753, 0.41558442]),\n",
       "   'test_recall': array([0.0620438 , 0.0620438 , 0.05656934, 0.0620438 , 0.05656934,\n",
       "          0.06934307, 0.06386861, 0.06021898, 0.05667276, 0.05850091])}],\n",
       " [10,\n",
       "  {'fit_time': array([3.27977562, 3.27743268, 3.23043323, 3.39290285, 3.28796196,\n",
       "          3.27818155, 3.27525091, 3.30007005, 3.3118794 , 3.64119339]),\n",
       "   'score_time': array([33.71241522, 33.2789104 , 33.9094646 , 32.51874447, 33.23638153,\n",
       "          33.16312027, 33.6003108 , 32.33820105, 34.64478898, 32.87940669]),\n",
       "   'test_roc_auc': array([0.67347826, 0.69045788, 0.6841564 , 0.68917171, 0.6698399 ,\n",
       "          0.67305192, 0.67540917, 0.66068371, 0.66621222, 0.69190701]),\n",
       "   'test_accuracy': array([0.93523652, 0.93618025, 0.93594432, 0.93582635, 0.93523652,\n",
       "          0.93618025, 0.93641618, 0.93641618, 0.93499292, 0.93475696]),\n",
       "   'test_precision': array([0.48275862, 0.68421053, 0.61904762, 0.59090909, 0.48484848,\n",
       "          0.66666667, 0.62857143, 0.8       , 0.43333333, 0.39285714]),\n",
       "   'test_recall': array([0.02554745, 0.02372263, 0.02372263, 0.02372263, 0.02919708,\n",
       "          0.02554745, 0.04014599, 0.02189781, 0.023766  , 0.02010969])}],\n",
       " [15,\n",
       "  {'fit_time': array([3.23497796, 3.25138545, 3.23709178, 3.33833981, 3.48795915,\n",
       "          3.69470406, 3.29504871, 3.54640508, 3.32039404, 3.42730856]),\n",
       "   'score_time': array([34.83030629, 34.93886662, 34.90942764, 34.13643408, 35.12988448,\n",
       "          35.03869152, 35.36162758, 35.95840573, 34.4152658 , 34.39082718]),\n",
       "   'test_roc_auc': array([0.70059276, 0.7233352 , 0.70485861, 0.70660368, 0.68213113,\n",
       "          0.69990336, 0.70770826, 0.68155461, 0.68294908, 0.70854542]),\n",
       "   'test_accuracy': array([0.93511856, 0.93559042, 0.93594432, 0.93618025, 0.93570839,\n",
       "          0.93677008, 0.93606229, 0.93570839, 0.93593676, 0.9351109 ]),\n",
       "   'test_precision': array([0.46428571, 0.55      , 0.60869565, 0.68421053, 0.54285714,\n",
       "          0.73076923, 0.58333333, 0.57142857, 0.5625    , 0.45714286]),\n",
       "   'test_recall': array([0.02372263, 0.02007299, 0.02554745, 0.02372263, 0.03467153,\n",
       "          0.03467153, 0.03832117, 0.02189781, 0.03290676, 0.02925046])}],\n",
       " [20,\n",
       "  {'fit_time': array([3.3752594 , 3.21782279, 3.24974632, 3.37867665, 3.32878327,\n",
       "          3.66702819, 3.23099589, 3.32589507, 3.31924582, 3.34270716]),\n",
       "   'score_time': array([36.65272951, 36.23260999, 36.24314475, 35.39174914, 36.10412145,\n",
       "          36.35557914, 36.03586364, 34.95449519, 35.57369399, 34.58788228]),\n",
       "   'test_roc_auc': array([0.71282173, 0.73633032, 0.73161144, 0.7181146 , 0.69451487,\n",
       "          0.71529648, 0.7165892 , 0.70435781, 0.7062747 , 0.73454964]),\n",
       "   'test_accuracy': array([0.93547245, 0.93547245, 0.93570839, 0.93594432, 0.93523652,\n",
       "          0.93653415, 0.93606229, 0.93547245, 0.9357008 , 0.93593676]),\n",
       "   'test_precision': array([0.52941176, 0.54545455, 0.63636364, 0.72727273, 0.47619048,\n",
       "          0.85714286, 0.65      , 0.55555556, 0.58333333, 0.6       ]),\n",
       "   'test_recall': array([0.01642336, 0.01094891, 0.01277372, 0.01459854, 0.01824818,\n",
       "          0.02189781, 0.02372263, 0.00912409, 0.01279707, 0.02193784])}]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_knn = pd.DataFrame(columns=[\"N\",\"solver\",\"score\",\"score_val0\",\"score_val1\",\"score_val2\",\"score_val3\",\"score_val4\",\"score_val5\",\"score_val6\",\"score_val7\",\"score_val8\",\"score_val9\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "\n",
    "for r in res_knn:\n",
    "    for k,v in r[1].items():\n",
    "      l = [r[0]]\n",
    "      l.append('lbfgs')\n",
    "      l.append(k)\n",
    "      for i in v:\n",
    "            l.append(i)\n",
    "      res_df_knn.loc[cnt]=l  \n",
    "      cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>solver</th>\n",
       "      <th>score</th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>3.346011</td>\n",
       "      <td>3.240500</td>\n",
       "      <td>3.246187</td>\n",
       "      <td>3.382666</td>\n",
       "      <td>3.298579</td>\n",
       "      <td>3.300749</td>\n",
       "      <td>3.308119</td>\n",
       "      <td>3.523702</td>\n",
       "      <td>3.592575</td>\n",
       "      <td>3.630630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>31.228169</td>\n",
       "      <td>31.406136</td>\n",
       "      <td>31.333480</td>\n",
       "      <td>30.432310</td>\n",
       "      <td>30.849423</td>\n",
       "      <td>31.047410</td>\n",
       "      <td>31.176363</td>\n",
       "      <td>31.958381</td>\n",
       "      <td>30.939871</td>\n",
       "      <td>30.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.631900</td>\n",
       "      <td>0.648876</td>\n",
       "      <td>0.654227</td>\n",
       "      <td>0.654328</td>\n",
       "      <td>0.619916</td>\n",
       "      <td>0.636993</td>\n",
       "      <td>0.640930</td>\n",
       "      <td>0.622747</td>\n",
       "      <td>0.626581</td>\n",
       "      <td>0.653691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.932051</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.932995</td>\n",
       "      <td>0.933939</td>\n",
       "      <td>0.931580</td>\n",
       "      <td>0.934765</td>\n",
       "      <td>0.932169</td>\n",
       "      <td>0.933231</td>\n",
       "      <td>0.934167</td>\n",
       "      <td>0.933931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.378049</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.329787</td>\n",
       "      <td>0.469136</td>\n",
       "      <td>0.360825</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.424658</td>\n",
       "      <td>0.415584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>0.056569</td>\n",
       "      <td>0.069343</td>\n",
       "      <td>0.063869</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.056673</td>\n",
       "      <td>0.058501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>3.279776</td>\n",
       "      <td>3.277433</td>\n",
       "      <td>3.230433</td>\n",
       "      <td>3.392903</td>\n",
       "      <td>3.287962</td>\n",
       "      <td>3.278182</td>\n",
       "      <td>3.275251</td>\n",
       "      <td>3.300070</td>\n",
       "      <td>3.311879</td>\n",
       "      <td>3.641193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>33.712415</td>\n",
       "      <td>33.278910</td>\n",
       "      <td>33.909465</td>\n",
       "      <td>32.518744</td>\n",
       "      <td>33.236382</td>\n",
       "      <td>33.163120</td>\n",
       "      <td>33.600311</td>\n",
       "      <td>32.338201</td>\n",
       "      <td>34.644789</td>\n",
       "      <td>32.879407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.673478</td>\n",
       "      <td>0.690458</td>\n",
       "      <td>0.684156</td>\n",
       "      <td>0.689172</td>\n",
       "      <td>0.669840</td>\n",
       "      <td>0.673052</td>\n",
       "      <td>0.675409</td>\n",
       "      <td>0.660684</td>\n",
       "      <td>0.666212</td>\n",
       "      <td>0.691907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935237</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.935237</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.934993</td>\n",
       "      <td>0.934757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.040146</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.020110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>3.234978</td>\n",
       "      <td>3.251385</td>\n",
       "      <td>3.237092</td>\n",
       "      <td>3.338340</td>\n",
       "      <td>3.487959</td>\n",
       "      <td>3.694704</td>\n",
       "      <td>3.295049</td>\n",
       "      <td>3.546405</td>\n",
       "      <td>3.320394</td>\n",
       "      <td>3.427309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>34.830306</td>\n",
       "      <td>34.938867</td>\n",
       "      <td>34.909428</td>\n",
       "      <td>34.136434</td>\n",
       "      <td>35.129884</td>\n",
       "      <td>35.038692</td>\n",
       "      <td>35.361628</td>\n",
       "      <td>35.958406</td>\n",
       "      <td>34.415266</td>\n",
       "      <td>34.390827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.723335</td>\n",
       "      <td>0.704859</td>\n",
       "      <td>0.706604</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>0.699903</td>\n",
       "      <td>0.707708</td>\n",
       "      <td>0.681555</td>\n",
       "      <td>0.682949</td>\n",
       "      <td>0.708545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935119</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.936062</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.935937</td>\n",
       "      <td>0.935111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.457143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.020073</td>\n",
       "      <td>0.025547</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.034672</td>\n",
       "      <td>0.034672</td>\n",
       "      <td>0.038321</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.032907</td>\n",
       "      <td>0.029250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>fit_time</td>\n",
       "      <td>3.375259</td>\n",
       "      <td>3.217823</td>\n",
       "      <td>3.249746</td>\n",
       "      <td>3.378677</td>\n",
       "      <td>3.328783</td>\n",
       "      <td>3.667028</td>\n",
       "      <td>3.230996</td>\n",
       "      <td>3.325895</td>\n",
       "      <td>3.319246</td>\n",
       "      <td>3.342707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>score_time</td>\n",
       "      <td>36.652730</td>\n",
       "      <td>36.232610</td>\n",
       "      <td>36.243145</td>\n",
       "      <td>35.391749</td>\n",
       "      <td>36.104121</td>\n",
       "      <td>36.355579</td>\n",
       "      <td>36.035864</td>\n",
       "      <td>34.954495</td>\n",
       "      <td>35.573694</td>\n",
       "      <td>34.587882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_roc_auc</td>\n",
       "      <td>0.712822</td>\n",
       "      <td>0.736330</td>\n",
       "      <td>0.731611</td>\n",
       "      <td>0.718115</td>\n",
       "      <td>0.694515</td>\n",
       "      <td>0.715296</td>\n",
       "      <td>0.716589</td>\n",
       "      <td>0.704358</td>\n",
       "      <td>0.706275</td>\n",
       "      <td>0.734550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_accuracy</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.935237</td>\n",
       "      <td>0.936534</td>\n",
       "      <td>0.936062</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.935701</td>\n",
       "      <td>0.935937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_precision</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>test_recall</td>\n",
       "      <td>0.016423</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.009124</td>\n",
       "      <td>0.012797</td>\n",
       "      <td>0.021938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     N solver           score  score_val0  score_val1  score_val2  score_val3  \\\n",
       "0    5  lbfgs        fit_time    3.346011    3.240500    3.246187    3.382666   \n",
       "1    5  lbfgs      score_time   31.228169   31.406136   31.333480   30.432310   \n",
       "2    5  lbfgs    test_roc_auc    0.631900    0.648876    0.654227    0.654328   \n",
       "3    5  lbfgs   test_accuracy    0.932051    0.935826    0.932995    0.933939   \n",
       "4    5  lbfgs  test_precision    0.354167    0.531250    0.378049    0.425000   \n",
       "5    5  lbfgs     test_recall    0.062044    0.062044    0.056569    0.062044   \n",
       "6   10  lbfgs        fit_time    3.279776    3.277433    3.230433    3.392903   \n",
       "7   10  lbfgs      score_time   33.712415   33.278910   33.909465   32.518744   \n",
       "8   10  lbfgs    test_roc_auc    0.673478    0.690458    0.684156    0.689172   \n",
       "9   10  lbfgs   test_accuracy    0.935237    0.936180    0.935944    0.935826   \n",
       "10  10  lbfgs  test_precision    0.482759    0.684211    0.619048    0.590909   \n",
       "11  10  lbfgs     test_recall    0.025547    0.023723    0.023723    0.023723   \n",
       "12  15  lbfgs        fit_time    3.234978    3.251385    3.237092    3.338340   \n",
       "13  15  lbfgs      score_time   34.830306   34.938867   34.909428   34.136434   \n",
       "14  15  lbfgs    test_roc_auc    0.700593    0.723335    0.704859    0.706604   \n",
       "15  15  lbfgs   test_accuracy    0.935119    0.935590    0.935944    0.936180   \n",
       "16  15  lbfgs  test_precision    0.464286    0.550000    0.608696    0.684211   \n",
       "17  15  lbfgs     test_recall    0.023723    0.020073    0.025547    0.023723   \n",
       "18  20  lbfgs        fit_time    3.375259    3.217823    3.249746    3.378677   \n",
       "19  20  lbfgs      score_time   36.652730   36.232610   36.243145   35.391749   \n",
       "20  20  lbfgs    test_roc_auc    0.712822    0.736330    0.731611    0.718115   \n",
       "21  20  lbfgs   test_accuracy    0.935472    0.935472    0.935708    0.935944   \n",
       "22  20  lbfgs  test_precision    0.529412    0.545455    0.636364    0.727273   \n",
       "23  20  lbfgs     test_recall    0.016423    0.010949    0.012774    0.014599   \n",
       "\n",
       "    score_val4  score_val5  score_val6  score_val7  score_val8  score_val9  \n",
       "0     3.298579    3.300749    3.308119    3.523702    3.592575    3.630630  \n",
       "1    30.849423   31.047410   31.176363   31.958381   30.939871   30.002239  \n",
       "2     0.619916    0.636993    0.640930    0.622747    0.626581    0.653691  \n",
       "3     0.931580    0.934765    0.932169    0.933231    0.934167    0.933931  \n",
       "4     0.329787    0.469136    0.360825    0.392857    0.424658    0.415584  \n",
       "5     0.056569    0.069343    0.063869    0.060219    0.056673    0.058501  \n",
       "6     3.287962    3.278182    3.275251    3.300070    3.311879    3.641193  \n",
       "7    33.236382   33.163120   33.600311   32.338201   34.644789   32.879407  \n",
       "8     0.669840    0.673052    0.675409    0.660684    0.666212    0.691907  \n",
       "9     0.935237    0.936180    0.936416    0.936416    0.934993    0.934757  \n",
       "10    0.484848    0.666667    0.628571    0.800000    0.433333    0.392857  \n",
       "11    0.029197    0.025547    0.040146    0.021898    0.023766    0.020110  \n",
       "12    3.487959    3.694704    3.295049    3.546405    3.320394    3.427309  \n",
       "13   35.129884   35.038692   35.361628   35.958406   34.415266   34.390827  \n",
       "14    0.682131    0.699903    0.707708    0.681555    0.682949    0.708545  \n",
       "15    0.935708    0.936770    0.936062    0.935708    0.935937    0.935111  \n",
       "16    0.542857    0.730769    0.583333    0.571429    0.562500    0.457143  \n",
       "17    0.034672    0.034672    0.038321    0.021898    0.032907    0.029250  \n",
       "18    3.328783    3.667028    3.230996    3.325895    3.319246    3.342707  \n",
       "19   36.104121   36.355579   36.035864   34.954495   35.573694   34.587882  \n",
       "20    0.694515    0.715296    0.716589    0.704358    0.706275    0.734550  \n",
       "21    0.935237    0.936534    0.936062    0.935472    0.935701    0.935937  \n",
       "22    0.476190    0.857143    0.650000    0.555556    0.583333    0.600000  \n",
       "23    0.018248    0.021898    0.023723    0.009124    0.012797    0.021938  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_auc = res_df.loc[res_df['score'] == 'test_roc_auc']\n",
    "\n",
    "lr_accuracy = res_df.loc[res_df['score'] == 'test_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.804297</td>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.818574</td>\n",
       "      <td>0.798959</td>\n",
       "      <td>0.806664</td>\n",
       "      <td>0.809276</td>\n",
       "      <td>0.811561</td>\n",
       "      <td>0.802313</td>\n",
       "      <td>0.808374</td>\n",
       "      <td>0.823414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.805934</td>\n",
       "      <td>0.819099</td>\n",
       "      <td>0.817921</td>\n",
       "      <td>0.806767</td>\n",
       "      <td>0.806359</td>\n",
       "      <td>0.806390</td>\n",
       "      <td>0.810111</td>\n",
       "      <td>0.802647</td>\n",
       "      <td>0.807718</td>\n",
       "      <td>0.821213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.803226</td>\n",
       "      <td>0.818893</td>\n",
       "      <td>0.818884</td>\n",
       "      <td>0.799487</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>0.813967</td>\n",
       "      <td>0.814267</td>\n",
       "      <td>0.801894</td>\n",
       "      <td>0.803144</td>\n",
       "      <td>0.823146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.803417</td>\n",
       "      <td>0.818060</td>\n",
       "      <td>0.823085</td>\n",
       "      <td>0.802515</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.804205</td>\n",
       "      <td>0.811605</td>\n",
       "      <td>0.797507</td>\n",
       "      <td>0.807413</td>\n",
       "      <td>0.822077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.800782</td>\n",
       "      <td>0.820506</td>\n",
       "      <td>0.817002</td>\n",
       "      <td>0.798568</td>\n",
       "      <td>0.804489</td>\n",
       "      <td>0.804794</td>\n",
       "      <td>0.815390</td>\n",
       "      <td>0.799240</td>\n",
       "      <td>0.801778</td>\n",
       "      <td>0.815344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_val0  score_val1  score_val2  score_val3  score_val4  score_val5  \\\n",
       "2     0.804297    0.820248    0.818574    0.798959    0.806664    0.809276   \n",
       "8     0.805934    0.819099    0.817921    0.806767    0.806359    0.806390   \n",
       "14    0.803226    0.818893    0.818884    0.799487    0.807092    0.813967   \n",
       "20    0.803417    0.818060    0.823085    0.802515    0.805310    0.804205   \n",
       "26    0.800782    0.820506    0.817002    0.798568    0.804489    0.804794   \n",
       "\n",
       "    score_val6  score_val7  score_val8  score_val9  \n",
       "2     0.811561    0.802313    0.808374    0.823414  \n",
       "8     0.810111    0.802647    0.807718    0.821213  \n",
       "14    0.814267    0.801894    0.803144    0.823146  \n",
       "20    0.811605    0.797507    0.807413    0.822077  \n",
       "26    0.815390    0.799240    0.801778    0.815344  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc = lr_auc.iloc[:, 3:13]\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_val0</th>\n",
       "      <th>score_val1</th>\n",
       "      <th>score_val2</th>\n",
       "      <th>score_val3</th>\n",
       "      <th>score_val4</th>\n",
       "      <th>score_val5</th>\n",
       "      <th>score_val6</th>\n",
       "      <th>score_val7</th>\n",
       "      <th>score_val8</th>\n",
       "      <th>score_val9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936298</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.935826</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.936534</td>\n",
       "      <td>0.936881</td>\n",
       "      <td>0.934639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.937006</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.939129</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936999</td>\n",
       "      <td>0.935229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.937360</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.935590</td>\n",
       "      <td>0.936770</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.934875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.935708</td>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.938658</td>\n",
       "      <td>0.934883</td>\n",
       "      <td>0.937242</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.938178</td>\n",
       "      <td>0.935229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.935944</td>\n",
       "      <td>0.938068</td>\n",
       "      <td>0.938893</td>\n",
       "      <td>0.935354</td>\n",
       "      <td>0.937832</td>\n",
       "      <td>0.937124</td>\n",
       "      <td>0.936652</td>\n",
       "      <td>0.938650</td>\n",
       "      <td>0.936055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_val0  score_val1  score_val2  score_val3  score_val4  score_val5  \\\n",
       "3     0.937242    0.936298    0.938893    0.938658    0.935826    0.937124   \n",
       "9     0.937006    0.935944    0.939129    0.939365    0.935354    0.938068   \n",
       "15    0.937360    0.935708    0.938658    0.938776    0.935590    0.936770   \n",
       "21    0.937124    0.935708    0.937596    0.938658    0.934883    0.937242   \n",
       "27    0.936652    0.935944    0.938068    0.938893    0.935354    0.937832   \n",
       "\n",
       "    score_val6  score_val7  score_val8  score_val9  \n",
       "3     0.937006    0.936534    0.936881    0.934639  \n",
       "9     0.937242    0.936416    0.936999    0.935229  \n",
       "15    0.936416    0.936180    0.938178    0.934875  \n",
       "21    0.937124    0.937124    0.938178    0.935229  \n",
       "27    0.937124    0.936652    0.938650    0.936055  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_accuracy = lr_accuracy.iloc[:, 3:13]\n",
    "roc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_cols = roc_accuracy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a880bd95f8>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9780>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd98d0>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9a20>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9b70>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9cc0>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9e10>,\n",
       " <matplotlib.lines.Line2D at 0x1a880bd9f60>,\n",
       " <matplotlib.lines.Line2D at 0x1a880be00f0>,\n",
       " <matplotlib.lines.Line2D at 0x1a880be0240>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.title(\"AUC\")\n",
    "plt.plot (lr_auc['C'], roc_aur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a880ee47f0>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2d668>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2d7b8>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2d908>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2da58>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2dba8>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2dcf8>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2de48>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f2df98>,\n",
       " <matplotlib.lines.Line2D at 0x1a880f33128>]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Accuracy\")\n",
    "plt.plot (lr_accuracy['C'], roc_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
